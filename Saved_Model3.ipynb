{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Loading In Needed Modules"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#Loading needed modules and classes/functions \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torchvision.datasets import ImageFolder \n",
    "from torchvision.io import read_image\n",
    "from torchvision.io import decode_image\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import marvin\n",
    "from marvin.tools.maps import Maps\n",
    "from marvin.tools.image import Image\n",
    "from marvin.utils.general.images import get_images_by_list\n",
    "from marvin import config\n",
    "from marvin.tools.cube import Cube\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix,r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image as image_PIL\n",
    "import PIL \n",
    "from PIL import ImageShow\n",
    "import time \n",
    "import hickle as hic\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=1.4)\n",
    "sns.set_style('ticks')\n",
    "\n",
    "from marvin import config\n",
    "from marvin.tools.image import Image\n",
    "config.setRelease('DR15')\n",
    "config.mode = 'local'\n",
    "config.download = True\n",
    "\n",
    "\n",
    "%matplotlib qt"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[0;34m[INFO]: \u001b[0mNo release version set. Setting default to DR15\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mpath /home/juanp/sas/mangawork/manga/spectro/redux/v2_4_3/drpall-v2_4_3.fits cannot be found. Setting drpall to None.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mpath /home/juanp/sas/mangawork/manga/spectro/analysis/v2_4_3/2.2.1/dapall-v2_4_3-2.2.1.fits cannot be found. Setting dapall to None.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mpath /home/juanp/sas/mangawork/manga/spectro/redux/v2_4_3/drpall-v2_4_3.fits cannot be found. Setting drpall to None.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mpath /home/juanp/sas/mangawork/manga/spectro/analysis/v2_4_3/2.2.1/dapall-v2_4_3-2.2.1.fits cannot be found. Setting dapall to None.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load in Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "\n",
    "\n",
    "data=pd.read_csv('CompleteTable.csv')  #Importing All MaNGA Data from DPRall Schema\n",
    "\n",
    "galaxy_list=np.loadtxt('Query Results',dtype=str) #Pulling Manga ID's of galaxies which satisfy log(M) > 9 and 0 < z < 0.1\n",
    "\n",
    "\n",
    "#Problem with image associated with manga id at galaxy_list[3548], mangaid- 1-135668\n",
    "galaxy_list=np.delete(galaxy_list,3548)\n",
    "\n",
    "galaxy_list=np.unique(galaxy_list)\n",
    "\n",
    "\n",
    "\n",
    "galaxy_index=np.zeros(len(galaxy_list)) \n",
    "for i in range (len(galaxy_list)): #Getting the index of these galaxies in the schema table\n",
    "    galaxy_index[i]=np.where(data.loc[:,'mangaid']==galaxy_list[i])[0][0]\n",
    "\n",
    "galaxy_index=np.array(galaxy_index,dtype=int) #Ensuring we have array that can be used to index, force int \n",
    "\n",
    "\n",
    "\n",
    "galaxies=data.iloc[galaxy_index] #DF of galaxies which satisfies the condition, contains all relevant schema data \n",
    "\n",
    "galaxies=galaxies.sort_values(by=['plateifu']) #Sorting galaxies by plateifu to match ImageFolder Output \n",
    "\n",
    "#Creating the arrays of the independent variables were are interested in, and dependent variable n \n",
    "\n",
    "mass=galaxies.loc[:,'nsa_sersic_mass']\n",
    "log_mass=np.log10(mass)\n",
    "\n",
    "SFR=galaxies.loc[:,'sfr_tot']\n",
    "log_SFR=np.log10(SFR)\n",
    "\n",
    "ha_flux=galaxies.loc[:,'emline_gflux_tot_ha_6564']\n",
    "\n",
    "mangaid=galaxies.loc[:,'mangaid']\n",
    "\n",
    "plateifu=galaxies.loc[:,'plateifu']\n",
    "\n",
    "if plateifu.all()==np.unique(plateifu).all() and mangaid.all()==np.unique(mangaid.all()):\n",
    "    print('Is Unique List of Galaxies')\n",
    "    \n",
    "else:\n",
    "    print('Try Again')\n",
    "\n",
    "\n",
    "z=galaxies.loc[:,'z']\n",
    "\n",
    "n=galaxies.loc[:,'nsa_sersic_n']\n",
    "n=np.array(n,dtype=np.float32)\n",
    "n=torch.from_numpy(n).to('cuda:0').reshape(-1,1)\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Is Unique List of Galaxies\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sanity Check Cell"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "\n",
    "#Sanity Check that Indexing is right \n",
    "# index_check=np.where(mangaid=='1-373175')[0][0]\n",
    "index_check=3588\n",
    "print(index_check)\n",
    "print(galaxies.iloc[index_check])\n",
    "print(mangaid.iloc[index_check])\n",
    "print(log_SFR.iloc[index_check])\n",
    "\n",
    "#1-177626\n",
    "\n",
    "image=ImageFolder('/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/')\n",
    "print(image[index_check])\n",
    "PIL.ImageShow.show(image[index_check][0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39msubprocess 6500 is still running\u001b[0m \u001b[0;36m(ResourceWarning)\u001b[0m\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3588\n",
      "plate                         9891\n",
      "ifudesign                     9102\n",
      "plateifu                 9891-9102\n",
      "mangaid                   1-436646\n",
      "drpallindx                   10915\n",
      "                         ...      \n",
      "sfr_1re                 0.00510849\n",
      "sfr_tot                 0.00548693\n",
      "htmID               15336624667054\n",
      "nsa_elpetro_mass       4.65987e+10\n",
      "nsa_sersic_mass         5.4664e+10\n",
      "Name: 3455, Length: 622, dtype: object\n",
      "1-436646\n",
      "-2.26067034286715\n",
      "(<PIL.Image.Image image mode=RGB size=562x562 at 0x7F820BBEE9D0>, 274)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "print(len(np.unique(mangaid)))\n",
    "print(len(image))\n",
    "len(plateifu)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3589\n",
      "3589\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3589"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# function to resize image\n",
    "def resize_image(src_image, size=(128,128), bg_color=\"white\"): \n",
    "    from PIL import Image, ImageOps \n",
    "    \n",
    "    # resize the image so the longest dimension matches our target size\n",
    "    src_image.thumbnail(size, Image.ANTIALIAS)\n",
    "    \n",
    "    # Create a new square background image\n",
    "    new_image = Image.new(\"RGB\", size, bg_color)\n",
    "    \n",
    "    # Paste the resized image into the center of the square background\n",
    "    new_image.paste(src_image, (int((size[0] - src_image.size[0]) / 2), int((size[1] - src_image.size[1]) / 2)))\n",
    "  \n",
    "    # return the resized image\n",
    "    return new_image\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setting Up DataLoaders"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "img_size=(128,128)\n",
    "\n",
    "# image=ImageFolder('/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/') #Picks up 3590 pictures, directory list has lenght 3637 however \n",
    "\n",
    "torch.manual_seed(15)\n",
    "np.random.seed(15)\n",
    "\n",
    "image_directory='/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3'\n",
    "classes= sorted(os.listdir(image_directory))\n",
    "\n",
    "\n",
    "\n",
    "batch_size=50\n",
    "image_copies=30\n",
    "\n",
    "def load_dataset(data_path):\n",
    "    # Load all the images\n",
    "    transformation = transforms.Compose([\n",
    "        # Randomly augment the image data\n",
    "            # Random horizontal flip\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "            # Random vertical flip\n",
    "        transforms.RandomVerticalFlip(0.3),\n",
    "        #Rotates the image by some angle\n",
    "        transforms.RandomRotation(0,360),\n",
    "        # transform to tensors\n",
    "        transforms.ToTensor(),\n",
    "        # Normalize the pixel values (in R, G, and B channels)\n",
    "        # transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    # Load all of the images, transforming them\n",
    "    full_dataset = torchvision.datasets.ImageFolder(\n",
    "        root=data_path,\n",
    "        # transform=transformation\n",
    "    )\n",
    "    \n",
    "    #This loop transforms the images and assigns them the correct label \n",
    "\n",
    "    full_dataset_v2 = []   \n",
    "    for i in range(len(full_dataset)): \n",
    "        for j in range(image_copies): #This loops makes it so we have \"image_copies\" copies of each galaxy image with different orientations \n",
    "            temp=transformation(resize_image(full_dataset[i][0]))\n",
    "            full_dataset_v2.append((temp,log_SFR.iloc[i],mangaid.iloc[i],z.iloc[i])) \n",
    "    \n",
    "    full_dataset=full_dataset_v2\n",
    "\n",
    "    print(len(full_dataset))\n",
    "\n",
    "\n",
    "    # Split into training (70% and testing (30%) datasets)\n",
    "    train_size = int(0.7 * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    \n",
    "    # use torch.utils.data.random_split for training/test split\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "    \n",
    "    # define a loader for the training data we can iterate through in 50-image batches\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # define a loader for the testing data we can iterate through in 50-image batches\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=0,\n",
    "        shuffle=False\n",
    "    )\n",
    "        \n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "# Get the iterative dataloaders for test and training data\n",
    "train_loader, test_loader = load_dataset(image_directory)\n",
    "batch_size = train_loader.batch_size\n",
    "print(\"Data loaders ready to read\", image_directory)\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ed4f06cab599>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;31m# Get the iterative dataloaders for test and training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data loaders ready to read\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-ed4f06cab599>\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(data_path)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_copies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#This loops makes it so we have \"image_copies\" copies of each galaxy image with different orientations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mtemp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransformation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresize_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mfull_dataset_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog_SFR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmangaid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-a4c443f40af6>\u001b[0m in \u001b[0;36mresize_image\u001b[0;34m(src_image, size, bg_color)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# resize the image so the longest dimension matches our target size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0msrc_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthumbnail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mANTIALIAS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Create a new square background image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mthumbnail\u001b[0;34m(self, size, resample, reducing_gap)\u001b[0m\n\u001b[1;32m   2253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2255\u001b[0;31m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreducing_gap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreducing_gap\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2257\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1863\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfactor_x\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfactor_y\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m                 \u001b[0mreduce_box\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_safe_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1865\u001b[0;31m                 \u001b[0mself\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactor_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_box\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1866\u001b[0m                 box = (\n\u001b[1;32m   1867\u001b[0m                     \u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mreduce_box\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfactor_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, factor, box)\u001b[0m\n\u001b[1;32m   1904\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1906\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1907\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m     def rotate(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Defining Model Architecture "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# Create a neural net class\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    \n",
    "    # Defining the Constructor\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # In the init function, we define each layer we will use in our model\n",
    "        \n",
    "        # Our images are RGB, so we have input channels = 3. \n",
    "        # We will apply 12 filters in the first convolutional layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # A second convolutional layer takes 12 input channels, and generates 24 outputs\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # We in the end apply max pooling with a kernel size of 2\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # A drop layer deletes 20% of the features to help prevent overfitting\n",
    "        self.drop = nn.Dropout2d(p=0.2)\n",
    "        \n",
    "        # Our 128x128 image tensors will be pooled twice with a kernel size of 2. 128/2/2 is 32.\n",
    "        # This means that our feature tensors are now 128 x 128, and we've generated 24 of them\n",
    "        \n",
    "        # We need to flatten these in order to feed them to a fully-connected layer\n",
    "        self.fc = nn.Linear(in_features=32 * 32 * 24, out_features=10)\n",
    "\n",
    "        self.fc1= nn.Linear(in_features=10, out_features=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x=x+1\n",
    "        \n",
    "        # In the forward function, pass the data through the layers we defined in the init function\n",
    "        # print(x)\n",
    "        # Use a ReLU activation function after layer 1 (convolution 1 and pool)\n",
    "        x=self.conv1(x)\n",
    "        \n",
    "        x=self.pool(x)\n",
    "       \n",
    "\n",
    "        x=F.relu(x)\n",
    "\n",
    "        \n",
    "      \n",
    " \n",
    "     \n",
    "        # Use a ReLU activation function after layer 2\n",
    "        x = F.relu(self.pool(self.conv2(x))) \n",
    "        \n",
    "        \n",
    "        # Select some features to drop to prevent overfitting (only drop during training)\n",
    "        x = F.dropout(self.drop(x), training=self.training)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(-1, 32 * 32 * 24)\n",
    "        # Feed to fully-connected layer to predict class\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        # Return class probabilities via a log_softmax function\n",
    "        x=F.relu(x) \n",
    "        \n",
    "        x= self.fc1(x)\n",
    "        # print(x)\n",
    "        return x\n",
    "    \n",
    "device = \"cpu\"\n",
    "if (torch.cuda.is_available()):\n",
    "    # if GPU available, use cuda (on a cpu, training will take a considerable length of time!)\n",
    "    device = \"cuda\"\n",
    "\n",
    "# Create an instance of the model class and allocate it to the device\n",
    "model = Net(num_classes=len(SFR)).to('cuda')\n",
    "\n",
    "print(model)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (drop): Dropout2d(p=0.2, inplace=False)\n",
      "  (fc): Linear(in_features=24576, out_features=10, bias=True)\n",
      "  (fc1): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loading Up the Saved Model "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "model.load_state_dict(torch.load('/home/juanp/Documents/SURP-2021/Models/SFR_Model_Rotation_30_Copies_Images'))\n",
    "model.eval()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (drop): Dropout2d(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=24576, out_features=10, bias=True)\n",
       "  (fc1): Linear(in_features=10, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Checking How Well the Model is Preforming "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "all_truths_train = [] \n",
    "all_preds_train = [] \n",
    "all_mangaid_train=[]\n",
    "all_z_train=[]\n",
    "for (data,target,target1,target2) in train_loader:\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    output=model(data)\n",
    "    all_truths_train.append(target.cpu().detach().numpy())\n",
    "    all_preds_train.append(output.cpu().detach().numpy()) \n",
    "    all_mangaid_train.append(target1)\n",
    "    all_z_train.append(target2)\n",
    "\n",
    "\n",
    "incomplete_batch_id_train=len(all_truths_train)-1\n",
    "\n",
    "remainder_train=len(all_truths_train[incomplete_batch_id_train])\n",
    "\n",
    "total_values_train=(len(all_truths_train)*batch_size)-(batch_size-remainder_train)\n",
    "\n",
    "\n",
    "\n",
    "all_truths_train_array=np.zeros(total_values_train)\n",
    "all_preds_train_array=np.zeros(total_values_train)\n",
    "all_mangaid_train_array=[]\n",
    "all_z_train_array=np.zeros(total_values_train)\n",
    "k=0\n",
    "while k < total_values_train:\n",
    "    for i in range(len(all_truths_train)):\n",
    "        if i<incomplete_batch_id_train:\n",
    "            for j in range(batch_size):\n",
    "                all_truths_train_array[k]=all_truths_train[i][j]\n",
    "                all_preds_train_array[k]=all_preds_train[i][j]\n",
    "                all_mangaid_train_array.append(all_mangaid_train[i][j])\n",
    "                all_z_train_array[k]=all_z_train[i][j]\n",
    "                k=k+1\n",
    "                \n",
    "\n",
    "\n",
    "        else:\n",
    "            i=incomplete_batch_id_train\n",
    "            for j in range(remainder_train):\n",
    "                all_truths_train_array[k]=all_truths_train[i][j]\n",
    "                all_preds_train_array[k]=all_preds_train[i][j]\n",
    "                all_mangaid_train_array.append(all_mangaid_train[i][j])\n",
    "                all_z_train_array[k]=all_z_train[i][j]\n",
    "                k=k+1\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "# all_truths_train=all_truths_train_array\n",
    "# all_preds_train=all_preds_train_array\n",
    "\n",
    "#Sanity Check \n",
    "print(all_mangaid_train[6][44],all_truths_train[6][44])\n",
    "print(all_mangaid_train_array[344],all_truths_train_array[344])\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1-373175 -1.8767849197941102\n",
      "1-373175 -1.8767849197941102\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "all_truths_test = [] \n",
    "all_preds_test = [] \n",
    "all_mangaid_test=[]\n",
    "all_z_test=[]\n",
    "for (data,target,target1,target2) in test_loader:\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    output=model(data)\n",
    "    all_truths_test.append(target.cpu().detach().numpy())\n",
    "    all_preds_test.append(output.cpu().detach().numpy()) \n",
    "    all_mangaid_test.append(target1)\n",
    "    all_z_test.append(target2)\n",
    "\n",
    "\n",
    "incomplete_batch_id_test=len(all_truths_test)-1\n",
    "\n",
    "remainder_test=len(all_truths_test[incomplete_batch_id_test])\n",
    "\n",
    "total_values_test=(len(all_truths_test)*batch_size)-(batch_size-remainder_test)\n",
    "\n",
    "\n",
    "\n",
    "all_truths_test_array=np.zeros(total_values_test)\n",
    "all_preds_test_array=np.zeros(total_values_test)\n",
    "all_mangaid_test_array=[]\n",
    "all_z_test_array=np.zeros(total_values_test)\n",
    "k=0\n",
    "while k < total_values_test:\n",
    "    for i in range(len(all_truths_test)):\n",
    "        if i<incomplete_batch_id_test:\n",
    "            for j in range(batch_size):\n",
    "                all_truths_test_array[k]=all_truths_test[i][j]\n",
    "                all_preds_test_array[k]=all_preds_test[i][j]\n",
    "                all_mangaid_test_array.append(all_mangaid_test[i][j])\n",
    "                all_z_test_array[k]=all_z_test[i][j]\n",
    "                k=k+1\n",
    "                \n",
    "\n",
    "\n",
    "        else:\n",
    "            i=incomplete_batch_id_test\n",
    "            for j in range(remainder_test):\n",
    "                all_truths_test_array[k]=all_truths_test[i][j]\n",
    "                all_preds_test_array[k]=all_preds_test[i][j]\n",
    "                all_mangaid_test_array.append(all_mangaid_test[i][j])\n",
    "                all_z_test_array[k]=all_z_test[i][j]\n",
    "                k=k+1\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "# all_truths_test=all_truths_test_array\n",
    "# all_preds_test=all_preds_test_array\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "def MSE(pred,truth,n):\n",
    "    return((1/n)*np.sum((pred-truth)**2))\n",
    "\n",
    "np.savetxt('Train_Truths',all_truths_train_array)\n",
    "np.savetxt('Train_Preds',all_preds_train_array)\n",
    "np.savetxt('Train_Mangaid',all_mangaid_train_array,fmt='%s')\n",
    "np.savetxt('Train_z',all_z_train_array)\n",
    "np.savetxt('Test_Truths',all_truths_test_array)\n",
    "np.savetxt('Test_Preds',all_preds_test_array)\n",
    "np.savetxt('Test_Mangaid',all_mangaid_test_array,fmt='%s')\n",
    "np.savetxt('Test_z',all_z_test_array)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "r2_train=r2_score(all_truths_train_array,all_preds_train_array)\n",
    "r2_test=r2_score(all_truths_test_array,all_preds_test_array)\n",
    "MSE_train=MSE(all_preds_train_array,all_truths_train_array,len(all_preds_train_array))\n",
    "MSE_test=MSE(all_preds_test_array,all_truths_test_array,len(all_truths_test_array))\n",
    "# np.savetxt('Train_Data',all_truths_train_array)\n",
    "# np.savetxt('Train_Label',all_preds_train_array)\n",
    "# np.savetxt('Test_Data',all_truths_test_array)\n",
    "# np.savetxt('Test_Label',all_preds_test_array)\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.subplot(1,2,1) \n",
    "plt.title('Test Data Set',fontsize=14)\n",
    "plt.scatter(all_truths_test_array, all_preds_test_array,color = 'b', alpha = 0.1*7/3)\n",
    "plt.xlabel('Test True Values',fontsize=14)\n",
    "plt.ylabel('Test Predicted Value',fontsize=14)\n",
    "plt.text(-1.5,-5.5,'R$^2$='+ str(round(r2_test,4)),fontsize=14)\n",
    "plt.text(-1.5,-6,'MSE='+str(round(MSE_test,4)),fontsize=14)\n",
    "plt.plot([-5,1],[-5,1],'r--')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title('Train Data Set',fontsize=14)\n",
    "plt.scatter(all_truths_train_array, all_preds_train_array,color = 'k', alpha = 0.1)\n",
    "plt.xlabel('Train True Values',fontsize=14)\n",
    "plt.ylabel('Train Predicted Value',fontsize=14)\n",
    "plt.plot([-5,1],[-5,1],'r--') \n",
    "plt.text(-1.5,-5.5,'R$^2$='+str(round(r2_train,4)),fontsize=14)\n",
    "plt.text(-1.5,-6,'MSE='+str(round(MSE_train,4)),fontsize=14)\n",
    "plt.show()\n",
    "# plt.savefig('/home/juanp/Documents/SURP-2021/Plots/Model 3/MSE Rotations 30 Copies of Images.pdf')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Making the Summary Plots"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "all_images_train = [] \n",
    "for (data,target,target1,target2) in train_loader:\n",
    "    data = data.to(device)\n",
    "    all_images_train.append(data.detach().cpu().numpy())\n",
    "    \n",
    "\n",
    "\n",
    "incomplete_batch_id_train=len(all_images_train)-1\n",
    "\n",
    "remainder_train=len(all_images_train[incomplete_batch_id_train])\n",
    "\n",
    "total_values_train=(len(all_images_train)*batch_size)-(batch_size-remainder_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all_images_train_array=[]\n",
    "# k=0\n",
    "# while k < total_values_train:\n",
    "for i in range(len(all_images_train)):\n",
    "    if i<incomplete_batch_id_train:\n",
    "        for j in range(batch_size):\n",
    "            all_images_train_array.append(np.dstack(all_images_train[i][j][0:3]))\n",
    "            # k=k+1\n",
    "            \n",
    "\n",
    "\n",
    "    else:\n",
    "        i=incomplete_batch_id_train\n",
    "        for j in range(remainder_train):\n",
    "            all_images_train_array.append(np.dstack(all_images_train[i][j][0:3]))\n",
    "            # k=k+1\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "# all_images_train=all_images_train_array\n",
    "\n",
    "# np.savetxt('Images_Train', all_images_train_array)\n",
    "hic.dump(all_images_train_array,'Images_Train')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "all_images_test = [] \n",
    "for (data,target,target1,target2) in test_loader:\n",
    "    data = data.to(device)\n",
    "    all_images_test.append(data.detach().cpu().numpy())\n",
    "    \n",
    "\n",
    "\n",
    "incomplete_batch_id_test=len(all_images_test)-1\n",
    "\n",
    "remainder_test=len(all_images_test[incomplete_batch_id_test])\n",
    "\n",
    "total_values_test=(len(all_images_test)*batch_size)-(batch_size-remainder_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all_images_test_array=[]\n",
    "# k=0\n",
    "# while k < total_values_test:\n",
    "for i in range(len(all_images_test)):\n",
    "    if i<incomplete_batch_id_test:\n",
    "        for j in range(batch_size):\n",
    "            all_images_test_array.append(np.dstack(all_images_test[i][j][0:3]))\n",
    "            # k=k+1\n",
    "            \n",
    "\n",
    "\n",
    "    else:\n",
    "        i=incomplete_batch_id_test\n",
    "        for j in range(remainder_test):\n",
    "            all_images_test_array.append(np.dstack(all_images_test[i][j][0:3]))\n",
    "            # k=k+1\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "# all_images_test=all_images_test_array\n",
    "\n",
    "# np.savetxt('Images_Test', all_images_test_array)\n",
    "hic.dump(all_images_test_array,'Images_Test')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "all_truths_train_array=np.loadtxt('Train_Truths')\n",
    "all_preds_train_array=np.loadtxt('Train_Preds')\n",
    "all_mangaid_train_array=np.loadtxt('Train_Mangaid',dtype=str)\n",
    "all_z_train_array=np.loadtxt('Train_z')\n",
    "all_truths_test_array=np.loadtxt('Test_Truths')\n",
    "all_preds_test_array=np.loadtxt('Test_Preds')\n",
    "all_mangaid_test_array=np.loadtxt('Test_Mangaid',dtype=str)\n",
    "all_z_test_array=np.loadtxt('Test_z')\n",
    "\n",
    "all_images_train_array=hic.load('Images_Train')\n",
    "all_images_test_array=hic.load('Images_Test')"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Provided argument 'file_obj' does not appear to be a valid hickle file! (Unable to open file (file signature not found))",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/hickle/hickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file_obj, path, safe)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0mh5f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose_flag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m         \u001b[0mh_root_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Solely used by v4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/hickle/hickle.py\u001b[0m in \u001b[0;36mfile_opener\u001b[0;34m(f, path, mode)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mh5f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (file signature not found)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a3ec11cf3351>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mall_z_test_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test_z'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mall_images_train_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Images_Train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mall_images_test_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Images_Test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/hickle/hickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file_obj, path, safe)\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         raise ValueError(\"Provided argument 'file_obj' does not appear to be a\"\n\u001b[0;32m--> 574\u001b[0;31m                          \" valid hickle file! (%s)\" % (error))\n\u001b[0m\u001b[1;32m    575\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;31m# Close the file if requested.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Provided argument 'file_obj' does not appear to be a valid hickle file! (Unable to open file (file signature not found))"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def delta(truths,preds):\n",
    "    return(np.abs(truths-preds))\n",
    "\n",
    "delta_train=delta(all_truths_train_array,all_preds_train_array)\n",
    "delta_test=delta(all_truths_test_array,all_preds_test_array)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# print(np.min(delta_train),np.max(delta_train),np.mean(delta_train))\n",
    "# print(np.min(delta_test),np.max(delta_test),np.mean(delta_test))\n",
    "\n",
    "\n",
    "# print(np.shape(np.where(all_mangaid_test_array=='1-392010')))\n",
    "\n",
    "# 1-37922 -3.161576348521903\n",
    "\n",
    "# print(all_mangaid_train_array[986],all_truths_train_array[986])\n",
    "\n",
    "a=np.where(mangaid=='1-37922')\n",
    "print(a)\n",
    "print(SFR.iloc[a])\n",
    "\n",
    "# plt.imshow(all_images_train_array[986])\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(array([229]),)\n",
      "2879    0.000689\n",
      "Name: sfr_tot, dtype: float64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# print(all_images_train[0][0].shape)\n",
    "# print(all_images_train_array[0].shape)\n",
    "\n",
    "\n",
    "x_loc=70\n",
    "y_loc_truth=105\n",
    "y_loc_pred=110\n",
    "y_loc_delta=115\n",
    "y_loc_z=120\n",
    "y_loc_mangaid=125\n",
    "\n",
    "#Index to chose a galaxy at random \n",
    "# i_1=np.random.choice(len(all_truths_train_array))\n",
    "# i_2=np.random.choice(len(all_truths_train_array))\n",
    "# i_3=np.random.choice(len(all_truths_train_array))\n",
    "# i_4=np.random.choice(len(all_truths_train_array)) \n",
    "# i_5=np.random.choice(len(all_truths_train_array))  \n",
    "# i_6=np.random.choice(len(all_truths_train_array)) \n",
    "# i_7=np.random.choice(len(all_truths_train_array)) \n",
    "# i_8=np.random.choice(len(all_truths_test_array)) \n",
    "# i_9=np.random.choice(len(all_truths_test_array)) \n",
    "# i_10=np.random.choice(len(all_truths_test_array)) \n",
    "\n",
    "#Finding the galaxies where the model preformed the best \n",
    "# best_index_train=np.argsort(delta_train)[:7]\n",
    "# best_index_test=np.argsort(delta_test)[:3]\n",
    "\n",
    "# i_1=best_index_train[0]\n",
    "# i_2=best_index_train[1]\n",
    "# i_3=best_index_train[2]\n",
    "# i_4=best_index_train[3] \n",
    "# i_5=best_index_train[4]  \n",
    "# i_6=best_index_train[5] \n",
    "# i_7=best_index_train[6] \n",
    "# i_8=best_index_test[0] \n",
    "# i_9=best_index_test[1] \n",
    "# i_10=best_index_test[2] \n",
    "\n",
    "#Finding the galaxies where the model preformed the worst \n",
    "\n",
    "worst_index_train=np.argsort(-delta_train)[:7]\n",
    "worst_index_test=np.argsort(-delta_test)[:3]\n",
    "\n",
    "i_1=worst_index_train[0]\n",
    "i_2=worst_index_train[1]\n",
    "i_3=worst_index_train[2]\n",
    "i_4=worst_index_train[3] \n",
    "i_5=worst_index_train[4]  \n",
    "i_6=worst_index_train[5] \n",
    "i_7=worst_index_train[6] \n",
    "i_8=worst_index_test[0] \n",
    "i_9=worst_index_test[1] \n",
    "i_10=worst_index_test[2] \n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.rc('font',size=7)\n",
    "plt.subplot(2,5,1)\n",
    "plt.imshow(all_images_train_array[i_1])\n",
    "plt.text(x_loc,y_loc_truth,'True log SFR='+str(round(all_truths_train_array[i_1],5)),color='white')\n",
    "plt.text(x_loc,y_loc_pred,'Pred log SFR='+str(round(all_preds_train_array[i_1],5)),color='white')\n",
    "plt.text(x_loc,y_loc_mangaid,'Manga-id:'+all_mangaid_train_array[i_1],color='white')\n",
    "plt.text(x_loc,y_loc_z,'z:'+str(round(all_z_train_array[i_1],5)),color='white')\n",
    "plt.text(x_loc,y_loc_delta,'Delta:'+str(round(delta_train[i_1],5)),color='white')\n",
    "plt.subplot(2,5,2)\n",
    "plt.imshow(all_images_train_array[i_2])\n",
    "plt.text(x_loc,y_loc_truth,'True log SFR='+str(round(all_truths_train_array[i_2],5)),color='white')\n",
    "plt.text(x_loc,y_loc_pred,'Pred log SFR='+str(round(all_preds_train_array[i_2],5)),color='white')\n",
    "plt.text(x_loc,y_loc_mangaid,'Manga-id:'+all_mangaid_train_array[i_2],color='white')\n",
    "plt.text(x_loc,y_loc_z,'z:'+str(round(all_z_train_array[i_2],5)),color='white')\n",
    "plt.text(x_loc,y_loc_delta,'Delta:'+str(round(delta_train[i_2],5)),color='white')\n",
    "plt.subplot(2,5,3)\n",
    "plt.imshow(all_images_train_array[i_3])\n",
    "plt.text(x_loc,y_loc_truth,'True log SFR='+str(round(all_truths_train_array[i_3],5)),color='white')\n",
    "plt.text(x_loc,y_loc_pred,'Pred log SFR='+str(round(all_preds_train_array[i_3],5)),color='white')\n",
    "plt.text(x_loc,y_loc_mangaid,'Manga-id:'+all_mangaid_train_array[i_3],color='white')\n",
    "plt.text(x_loc,y_loc_z,'z:'+str(round(all_z_train_array[i_3],5)),color='white')\n",
    "plt.text(x_loc,y_loc_delta,'Delta:'+str(round(delta_train[i_3],5)),color='white')\n",
    "plt.subplot(2,5,4)\n",
    "plt.imshow(all_images_train_array[i_4])\n",
    "plt.text(x_loc,y_loc_truth,'True log SFR='+str(round(all_truths_train_array[i_4],5)),color='white')\n",
    "plt.text(x_loc,y_loc_pred,'Pred log SFR='+str(round(all_preds_train_array[i_4],5)),color='white')\n",
    "plt.text(x_loc,y_loc_mangaid,'Manga-id:'+all_mangaid_train_array[i_4],color='white')\n",
    "plt.text(x_loc,y_loc_z,'z:'+str(round(all_z_train_array[i_4],5)),color='white')\n",
    "plt.text(x_loc,y_loc_delta,'Delta:'+str(round(delta_train[i_4],5)),color='white')\n",
    "plt.subplot(2,5,5)\n",
    "plt.imshow(all_images_train_array[i_5])\n",
    "plt.text(x_loc,y_loc_truth,'True log SFR='+str(round(all_truths_train_array[i_5],5)),color='white')\n",
    "plt.text(x_loc,y_loc_pred,'Pred log SFR='+str(round(all_preds_train_array[i_5],5)),color='white')\n",
    "plt.text(x_loc,y_loc_mangaid,'Manga-id:'+all_mangaid_train_array[i_5],color='white')\n",
    "plt.text(x_loc,y_loc_z,'z:'+str(round(all_z_train_array[i_5],5)),color='white')\n",
    "plt.text(x_loc,y_loc_delta,'Delta:'+str(round(delta_train[i_5],5)),color='white')\n",
    "plt.subplot(2,5,6)\n",
    "plt.imshow(all_images_train_array[i_6])\n",
    "plt.text(x_loc,y_loc_truth,'True log SFR='+str(round(all_truths_train_array[i_6],5)),color='white')\n",
    "plt.text(x_loc,y_loc_pred,'Pred log SFR='+str(round(all_preds_train_array[i_6],5)),color='white')\n",
    "plt.text(x_loc,y_loc_mangaid,'Manga-id:'+all_mangaid_train_array[i_6],color='white')\n",
    "plt.text(x_loc,y_loc_z,'z:'+str(round(all_z_train_array[i_6],5)),color='white')\n",
    "plt.text(x_loc,y_loc_delta,'Delta:'+str(round(delta_train[i_6],5)),color='white')\n",
    "plt.subplot(2,5,7)\n",
    "plt.imshow(all_images_train_array[i_7])\n",
    "plt.text(x_loc,y_loc_truth,'True log SFR='+str(round(all_truths_train_array[i_7],5)),color='white')\n",
    "plt.text(x_loc,y_loc_pred,'Pred log SFR='+str(round(all_preds_train_array[i_7],5)),color='white')\n",
    "plt.text(x_loc,y_loc_mangaid,'Manga-id:'+all_mangaid_train_array[i_7],color='white')\n",
    "plt.text(x_loc,y_loc_z,'z:'+str(round(all_z_train_array[i_7],5)),color='white')\n",
    "plt.text(x_loc,y_loc_delta,'Delta:'+str(round(delta_train[i_7],5)),color='white')\n",
    "plt.subplot(2,5,8)\n",
    "plt.imshow(all_images_test_array[i_8])\n",
    "plt.text(x_loc,y_loc_truth,'True log SFR='+str(round(all_truths_test_array[i_8],5)),color='white')\n",
    "plt.text(x_loc,y_loc_pred,'Pred log SFR='+str(round(all_preds_test_array[i_8],5)),color='white')\n",
    "plt.text(x_loc,y_loc_mangaid,'Manga-id:'+all_mangaid_test_array[i_8],color='white')\n",
    "plt.text(x_loc,y_loc_z,'z:'+str(round(all_z_test_array[i_8],5)),color='white')\n",
    "plt.text(x_loc,y_loc_delta,'Delta:'+str(round(delta_test[i_8],5)),color='white')\n",
    "plt.show()\n",
    "plt.subplot(2,5,9)\n",
    "plt.imshow(all_images_test_array[i_9])\n",
    "plt.text(x_loc,y_loc_truth,'True log SFR='+str(round(all_truths_test_array[i_9],5)),color='white')\n",
    "plt.text(x_loc,y_loc_pred,'Pred log SFR='+str(round(all_preds_test_array[i_9],5)),color='white')\n",
    "plt.text(x_loc,y_loc_mangaid,'Manga-id:'+all_mangaid_test_array[i_9],color='white')\n",
    "plt.text(x_loc,y_loc_z,'z:'+str(round(all_z_test_array[i_9],5)),color='white')\n",
    "plt.text(x_loc,y_loc_delta,'Delta:'+str(round(delta_test[i_9],5)),color='white')\n",
    "plt.show()\n",
    "plt.subplot(2,5,10)\n",
    "plt.imshow(all_images_test_array[i_10])\n",
    "plt.text(x_loc,y_loc_truth,'True log SFR='+str(round(all_truths_test_array[i_10],5)),color='white')\n",
    "plt.text(x_loc,y_loc_pred,'Pred log SFR='+str(round(all_preds_test_array[i_10],5)),color='white')\n",
    "plt.text(x_loc,y_loc_mangaid,'Manga-id:'+all_mangaid_test_array[i_10],color='white')\n",
    "plt.text(x_loc,y_loc_z,'z:'+str(round(all_z_test_array[i_10],5)),color='white')\n",
    "plt.text(x_loc,y_loc_delta,'Delta:'+str(round(delta_test[i_10],5)),color='white')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "332de2e570cd2f6fcfd1dc3718047bca654fabf3a28e9f4985b0d5046bfd1195"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}