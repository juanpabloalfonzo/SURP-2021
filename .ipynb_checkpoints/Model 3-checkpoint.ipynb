{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: Predict Star Formation Variables (sSFR, SFR, M*, age) Based on Visual Morphology (galaxy image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;34m[INFO]: \u001b[0mNo release version set. Setting default to DR15\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mpath /home/juanp/sas/mangawork/manga/spectro/redux/v2_4_3/drpall-v2_4_3.fits cannot be found. Setting drpall to None.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mpath /home/juanp/sas/mangawork/manga/spectro/analysis/v2_4_3/2.2.1/dapall-v2_4_3-2.2.1.fits cannot be found. Setting dapall to None.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mpath /home/juanp/sas/mangawork/manga/spectro/redux/v2_4_3/drpall-v2_4_3.fits cannot be found. Setting drpall to None.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mpath /home/juanp/sas/mangawork/manga/spectro/analysis/v2_4_3/2.2.1/dapall-v2_4_3-2.2.1.fits cannot be found. Setting dapall to None.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Loading needed modules and classes/functions \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torchvision.datasets import ImageFolder \n",
    "from torchvision.io import read_image\n",
    "from torchvision.io import decode_image\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import marvin\n",
    "from marvin.tools.maps import Maps\n",
    "from marvin.tools.image import Image\n",
    "from marvin.utils.general.images import get_images_by_list\n",
    "from marvin import config\n",
    "from marvin.tools.cube import Cube\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image as image_PIL\n",
    "\n",
    "#set config attributes and turn on global downloads of Marvin data\n",
    "config.setRelease('DR15')\n",
    "config.mode = 'local'\n",
    "config.download = True\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib qt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data from Schema Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data=pd.read_csv('CompleteTable.csv')  #Importing All MaNGA Data from DPRall Schema\n",
    "\n",
    "galaxy_list=np.loadtxt('Query Results',dtype=str) #Pulling Manga ID's of galaxies which satisfy log(M) > 9 and 0 < z < 0.1\n",
    "\n",
    "\n",
    "#Problem with image associated with manga id at galaxy_list[3548], mangaid- 1-135668\n",
    "galaxy_list=np.delete(galaxy_list,3548)\n",
    "\n",
    "galaxy_list=np.unique(galaxy_list)\n",
    "\n",
    "\n",
    "galaxy_index=np.zeros(len(galaxy_list)) \n",
    "for i in range (len(galaxy_list)): #Getting the index of these galaxies in the schema table\n",
    "    galaxy_index[i]=np.where(data.loc[:,'mangaid']==galaxy_list[i])[0][0]\n",
    "\n",
    "galaxy_index=np.array(galaxy_index,dtype=int) #Ensuring we have array that can be used to index, force int \n",
    "\n",
    "galaxies=data.iloc[galaxy_index] #DF of galaxies which satisfies the condition, contains all relevant schema data \n",
    "\n",
    "galaxies=galaxies.sort_values(by=['plateifu']) #Sorting galaxies by plateifu to match ImageFolder Output \n",
    "\n",
    "#Creating the arrays of the independent variables were are interested in, and dependent variable n \n",
    "\n",
    "mass=galaxies.loc[:,'nsa_sersic_mass']\n",
    "log_mass=np.log10(mass)\n",
    "\n",
    "SFR=galaxies.loc[:,'sfr_tot']\n",
    "log_SFR=np.log10(SFR)\n",
    "\n",
    "ha_flux=galaxies.loc[:,'emline_gflux_tot_ha_6564']\n",
    "\n",
    "n=galaxies.loc[:,'nsa_sersic_n']\n",
    "n=np.array(n,dtype=np.float32)\n",
    "n=torch.from_numpy(n).to('cuda:0').reshape(-1,1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Importing Images from their Downloaded Locations \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_locations=[]\n",
    "# for i in range (len(galaxy_list)):\n",
    "#     image_locations.append(Image(galaxy_list[i]).filename)\n",
    "    \n",
    "# image_locations=np.array(image_locations,dtype=str)\n",
    "# np.savetxt('Image Directories',image_locations,fmt='%s')\n",
    "\n",
    "image_locations=np.loadtxt('Image Directories',dtype=str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# function to resize image\n",
    "def resize_image(src_image, size=(128,128), bg_color=\"white\"): \n",
    "    from PIL import Image, ImageOps \n",
    "    \n",
    "    # resize the image so the longest dimension matches our target size\n",
    "    src_image.thumbnail(size, Image.ANTIALIAS)\n",
    "    \n",
    "    # Create a new square background image\n",
    "    new_image = Image.new(\"RGB\", size, bg_color)\n",
    "    \n",
    "    # Paste the resized image into the center of the square background\n",
    "    new_image.paste(src_image, (int((size[0] - src_image.size[0]) / 2), int((size[1] - src_image.size[1]) / 2)))\n",
    "  \n",
    "    # return the resized image\n",
    "    return new_image\n",
    "\n",
    "\n",
    "\n",
    "# training_folder_name = '/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/'\n",
    "\n",
    "# # New location for the resized images\n",
    "# train_folder = '/home/juanp/Documents/Resized MaNGA Pictures'\n",
    "\n",
    "\n",
    "# # Create resized copies of all of the source images\n",
    "# size = (128,128)\n",
    "\n",
    "# # Create the output folder if it doesn't already exist\n",
    "# if os.path.exists(train_folder):\n",
    "#     shutil.rmtree(train_folder)\n",
    "\n",
    "# # Loop through each subfolder in the input folder\n",
    "# print('Transforming images...')\n",
    "# for root, folders, files in os.walk(training_folder_name):\n",
    "#     for sub_folder in folders:\n",
    "#         print('processing folder ' + sub_folder)\n",
    "#         # Create a matching subfolder in the output dir\n",
    "#         saveFolder = os.path.join(train_folder,sub_folder)\n",
    "#         if not os.path.exists(saveFolder):\n",
    "#             os.makedirs(saveFolder)\n",
    "#         # Loop through the files in the subfolder\n",
    "#         file_names = os.listdir(os.path.join(root,sub_folder))\n",
    "#         for file_name in file_names:\n",
    "#             # Open the file\n",
    "#             file_path = os.path.join(root,sub_folder, file_name)\n",
    "#             #print(\"reading \" + file_path)\n",
    "#             try:\n",
    "#                 image = image_PIL.open(file_path)\n",
    "#                  # Create a resized version and save it\n",
    "#                 resized_image = resize_image(image, size)\n",
    "#                 saveAs = os.path.join(saveFolder, file_name)\n",
    "#                 #print(\"writing \" + saveAs)\n",
    "#                 resized_image.save(saveAs)\n",
    "#             except:\n",
    "#                 print(file_path)\n",
    "           \n",
    "\n",
    "# print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting the Images into DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaders ready to read /home/juanp/sas/dr15/manga/spectro/redux/v2_4_3\n"
     ]
    }
   ],
   "source": [
    "img_size=(128,128)\n",
    "\n",
    "# image=ImageFolder('/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/') #Picks up 3590 pictures, directory list has lenght 3637 however \n",
    "\n",
    "image_directory='/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3'\n",
    "classes= sorted(os.listdir(image_directory))\n",
    "\n",
    "def load_dataset(data_path):\n",
    "    # Load all the images\n",
    "    transformation = transforms.Compose([\n",
    "        # Randomly augment the image data\n",
    "            # Random horizontal flip\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "            # Random vertical flip\n",
    "        transforms.RandomVerticalFlip(0.3),\n",
    "        # transform to tensors\n",
    "        transforms.ToTensor(),\n",
    "        # Normalize the pixel values (in R, G, and B channels)\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    # Load all of the images, transforming them\n",
    "    full_dataset = torchvision.datasets.ImageFolder(\n",
    "        root=data_path,\n",
    "        # transform=transformation\n",
    "    )\n",
    "    \n",
    "    #This loop transforms the images and assigns them the correct label \n",
    "\n",
    "    full_dataset_v2 = []   \n",
    "    for i in range(len(full_dataset)): \n",
    "        temp=transformation(resize_image(full_dataset[i][0]))\n",
    "        full_dataset_v2.append((temp,log_SFR.iloc[i])) \n",
    "    \n",
    "    full_dataset=full_dataset_v2\n",
    "\n",
    "\n",
    "    # Split into training (70% and testing (30%) datasets)\n",
    "    train_size = int(0.7 * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    \n",
    "    # use torch.utils.data.random_split for training/test split\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "    \n",
    "    # define a loader for the training data we can iterate through in 50-image batches\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=10,\n",
    "        num_workers=0,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # define a loader for the testing data we can iterate through in 50-image batches\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=10,\n",
    "        num_workers=0,\n",
    "        shuffle=False\n",
    "    )\n",
    "        \n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "# Get the iterative dataloaders for test and training data\n",
    "train_loader, test_loader = load_dataset(image_directory)\n",
    "batch_size = train_loader.batch_size\n",
    "print(\"Data loaders ready to read\", image_directory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 3589\n",
      "    Root location: /home/juanp/sas/dr15/manga/spectro/redux/v2_4_3\n",
      "3637\n",
      "3589\n",
      "3589\n"
     ]
    }
   ],
   "source": [
    "print(ImageFolder(image_directory))\n",
    "print(len(image_locations))\n",
    "print(len(np.unique(image_locations)))\n",
    "print(len(np.unique(galaxy_list)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# full_dataset = torchvision.datasets.ImageFolder(\n",
    "#         root='/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/7968',\n",
    "#         # transform=transformation\n",
    "#     ) \n",
    "\n",
    "# full_dataset_v2 = []   \n",
    "# for i in range(len(full_dataset)): \n",
    "#     full_dataset_v2.append((resize_image(full_dataset[i][0]) , i)) \n",
    "\n",
    "# print(full_dataset_v2)\n",
    "\n",
    "\n",
    "# print(full_dataset[0][1])\n",
    "# for i in range(len(full_dataset)): \n",
    "#         full_dataset[i] = (resize_image(full_dataset[i][0]) , 0) \n",
    "        # full_dataset[i][0] = resize_image(full_dataset[i][0])\n",
    "        # full_dataset[i][1] = correct_label(correct_manga_id) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(12, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (drop): Dropout2d(p=0.2, inplace=False)\n",
      "  (fc): Linear(in_features=24576, out_features=10, bias=True)\n",
      "  (fc1): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create a neural net class\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    \n",
    "    # Defining the Constructor\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # In the init function, we define each layer we will use in our model\n",
    "        \n",
    "        # Our images are RGB, so we have input channels = 3. \n",
    "        # We will apply 12 filters in the first convolutional layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # A second convolutional layer takes 12 input channels, and generates 24 outputs\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # We in the end apply max pooling with a kernel size of 2\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # A drop layer deletes 20% of the features to help prevent overfitting\n",
    "        self.drop = nn.Dropout2d(p=0.2)\n",
    "        \n",
    "        # Our 128x128 image tensors will be pooled twice with a kernel size of 2. 128/2/2 is 32.\n",
    "        # This means that our feature tensors are now 128 x 128, and we've generated 24 of them\n",
    "        \n",
    "        # We need to flatten these in order to feed them to a fully-connected layer\n",
    "        self.fc = nn.Linear(in_features=32 * 32 * 24, out_features=10)\n",
    "\n",
    "        self.fc1= nn.Linear(in_features=10, out_features=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=x+1\n",
    "        \n",
    "        # In the forward function, pass the data through the layers we defined in the init function\n",
    "        # print(x)\n",
    "        # Use a ReLU activation function after layer 1 (convolution 1 and pool)\n",
    "        x=self.conv1(x)\n",
    "        \n",
    "        x=self.pool(x)\n",
    "       \n",
    "\n",
    "        x=F.relu(x)\n",
    "\n",
    "        \n",
    "      \n",
    " \n",
    "     \n",
    "        # Use a ReLU activation function after layer 2\n",
    "        x = F.relu(self.pool(self.conv2(x))) \n",
    "        \n",
    "        \n",
    "        # Select some features to drop to prevent overfitting (only drop during training)\n",
    "        x = F.dropout(self.drop(x), training=self.training)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(-1, 32 * 32 * 24)\n",
    "        # Feed to fully-connected layer to predict class\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        # Return class probabilities via a log_softmax function\n",
    "        x=F.relu(x) \n",
    "        \n",
    "        x= self.fc1(x)\n",
    "        # print(x)\n",
    "        return x\n",
    "    \n",
    "device = \"cpu\"\n",
    "if (torch.cuda.is_available()):\n",
    "    # if GPU available, use cuda (on a cpu, training will take a considerable length of time!)\n",
    "    device = \"cuda\"\n",
    "\n",
    "# Create an instance of the model class and allocate it to the device\n",
    "model = Net(num_classes=len(SFR)).to('cuda')\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Training Loop/Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    print(\"Epoch:\", epoch)\n",
    "    # Process the images in batches\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        target=target.float()\n",
    "        # print(target.shape)\n",
    "        target=target.reshape(-1,1)\n",
    "        # Use the CPU or GPU as appropriate\n",
    "        # Recall that GPU is optimized for the operations we are dealing with\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Reset the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Push the data forward through the model layers\n",
    "    \n",
    "        output = model(data)\n",
    "\n",
    "        \n",
    "        # Get the loss\n",
    "        loss = loss_criteria(output, target)\n",
    "        if batch_idx==0:\n",
    "            print(output,target,output-target,loss)\n",
    "        # Keep a running total\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "       \n",
    "        \n",
    "        # Print metrics so we see some progress\n",
    "        # print('\\tTraining batch {} Loss: {:.6f}'.format(batch_idx + 1, loss.item()))\n",
    "            \n",
    "    # return average loss for the epoch\n",
    "    avg_loss = train_loss / (batch_idx+1)\n",
    "    print('Training set: Average loss: {:.6f}'.format(avg_loss))\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Test Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    # Switch the model to evaluation mode (so we don't backpropagate or drop)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        batch_count = 0\n",
    "        for data, target in test_loader:\n",
    "            target=target.float()\n",
    "            target=target.reshape(-1,1)\n",
    "            batch_count += 1\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # Get the predicted classes for this batch\n",
    "            output = model(data)\n",
    "            \n",
    "            # Calculate the loss for this batch\n",
    "            test_loss += loss_criteria(output, target).item()\n",
    "            \n",
    "            # Calculate the accuracy for this batch\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            correct += torch.sum(target==predicted).item()\n",
    "\n",
    "    # Calculate the average loss and total accuracy for this epoch\n",
    "    avg_loss = test_loss / batch_count\n",
    "    print('Validation set: Average loss: {:.6f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        avg_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    # return average loss for the epoch\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143],\n",
      "        [-0.5092]], device='cuda:0') tensor([[-0.0410],\n",
      "        [ 0.1527],\n",
      "        [-0.1019],\n",
      "        [ 0.1946],\n",
      "        [ 0.1206],\n",
      "        [ 0.4212],\n",
      "        [ 0.0094],\n",
      "        [-0.0224],\n",
      "        [ 0.0140],\n",
      "        [-0.0789]], device='cuda:0', grad_fn=<SubBackward0>) tensor(0.2722, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Training set: Average loss: 0.470495\n",
      "Validation set: Average loss: 100.247487, Accuracy: 0/1077 (0%)\n",
      "\n",
      "978\n",
      "Epoch: 978\n",
      "tensor([[-0.7059],\n",
      "        [-2.3147],\n",
      "        [-2.4827],\n",
      "        [-0.2570],\n",
      "        [-0.9199],\n",
      "        [-1.6143],\n",
      "        [-0.7703],\n",
      "        [-0.5485],\n",
      "        [-0.4619],\n",
      "        [-0.7489]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[-0.6700],\n",
      "        [-2.1638],\n",
      "        [-2.3606],\n",
      "        [-0.2278],\n",
      "        [-0.7998],\n",
      "        [-1.5897],\n",
      "        [-0.7477],\n",
      "        [-0.5973],\n",
      "        [-0.4143],\n",
      "        [-0.5092]], device='cuda:0') tensor([[-0.0359],\n",
      "        [-0.1510],\n",
      "        [-0.1221],\n",
      "        [-0.0292],\n",
      "        [-0.1201],\n",
      "        [-0.0247],\n",
      "        [-0.0225],\n",
      "        [ 0.0488],\n",
      "        [-0.0476],\n",
      "        [-0.2397]], device='cuda:0', grad_fn=<SubBackward0>) tensor(0.1175, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Training set: Average loss: 0.508274\n",
      "Validation set: Average loss: 99.984271, Accuracy: 0/1077 (0%)\n",
      "\n",
      "979\n",
      "Epoch: 979\n",
      "tensor([[-0.8888],\n",
      "        [-2.0360],\n",
      "        [-2.2801],\n",
      "        [-0.2820],\n",
      "        [-0.7971],\n",
      "        [-1.7884],\n",
      "        [-0.8304],\n",
      "        [-0.9015],\n",
      "        [-0.6521],\n",
      "        [-0.5779]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[-0.6700],\n",
      "        [-2.1638],\n",
      "        [-2.3606],\n",
      "        [-0.2278],\n",
      "        [-0.7998],\n",
      "        [-1.5897],\n",
      "        [-0.7477],\n",
      "        [-0.5973],\n",
      "        [-0.4143],\n",
      "        [-0.5092]], device='cuda:0') tensor([[-0.2187],\n",
      "        [ 0.1277],\n",
      "        [ 0.0804],\n",
      "        [-0.0542],\n",
      "        [ 0.0027],\n",
      "        [-0.1987],\n",
      "        [-0.0827],\n",
      "        [-0.3042],\n",
      "        [-0.2378],\n",
      "        [-0.0687]], device='cuda:0', grad_fn=<SubBackward0>) tensor(0.2737, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Training set: Average loss: 0.511638\n",
      "Validation set: Average loss: 104.163632, Accuracy: 0/1077 (0%)\n",
      "\n",
      "980\n",
      "Epoch: 980\n",
      "tensor([[-0.5509],\n",
      "        [-1.8618],\n",
      "        [-2.2742],\n",
      "        [-0.3632],\n",
      "        [-0.9012],\n",
      "        [-1.1474],\n",
      "        [-0.7223],\n",
      "        [-0.9570],\n",
      "        [-0.6108],\n",
      "        [-0.6176]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[-0.6700],\n",
      "        [-2.1638],\n",
      "        [-2.3606],\n",
      "        [-0.2278],\n",
      "        [-0.7998],\n",
      "        [-1.5897],\n",
      "        [-0.7477],\n",
      "        [-0.5973],\n",
      "        [-0.4143],\n",
      "        [-0.5092]], device='cuda:0') tensor([[ 0.1191],\n",
      "        [ 0.3019],\n",
      "        [ 0.0863],\n",
      "        [-0.1354],\n",
      "        [-0.1014],\n",
      "        [ 0.4423],\n",
      "        [ 0.0255],\n",
      "        [-0.3597],\n",
      "        [-0.1965],\n",
      "        [-0.1084]], device='cuda:0', grad_fn=<SubBackward0>) tensor(0.5174, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Training set: Average loss: 0.493030\n",
      "Validation set: Average loss: 102.505118, Accuracy: 0/1077 (0%)\n",
      "\n",
      "981\n",
      "Epoch: 981\n",
      "tensor([[-0.8502],\n",
      "        [-2.1144],\n",
      "        [-2.3835],\n",
      "        [-0.2928],\n",
      "        [-0.8114],\n",
      "        [-1.7093],\n",
      "        [-1.0547],\n",
      "        [-0.8230],\n",
      "        [-0.4143],\n",
      "        [-0.5757]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[-0.6700],\n",
      "        [-2.1638],\n",
      "        [-2.3606],\n",
      "        [-0.2278],\n",
      "        [-0.7998],\n",
      "        [-1.5897],\n",
      "        [-0.7477],\n",
      "        [-0.5973],\n",
      "        [-0.4143],\n",
      "        [-0.5092]], device='cuda:0') tensor([[-1.8019e-01],\n",
      "        [ 4.9349e-02],\n",
      "        [-2.2887e-02],\n",
      "        [-6.5003e-02],\n",
      "        [-1.1644e-02],\n",
      "        [-1.1959e-01],\n",
      "        [-3.0701e-01],\n",
      "        [-2.2567e-01],\n",
      "        [-4.3213e-05],\n",
      "        [-6.6554e-02]], device='cuda:0', grad_fn=<SubBackward0>) tensor(0.2037, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Training set: Average loss: 0.489655\n",
      "Validation set: Average loss: 97.674693, Accuracy: 0/1077 (0%)\n",
      "\n",
      "982\n",
      "Epoch: 982\n",
      "tensor([[-1.0303],\n",
      "        [-2.1625],\n",
      "        [-2.0861],\n",
      "        [-0.2590],\n",
      "        [-0.7838],\n",
      "        [-1.7981],\n",
      "        [-0.9263],\n",
      "        [-0.6455],\n",
      "        [-0.6751],\n",
      "        [-0.7353]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[-0.6700],\n",
      "        [-2.1638],\n",
      "        [-2.3606],\n",
      "        [-0.2278],\n",
      "        [-0.7998],\n",
      "        [-1.5897],\n",
      "        [-0.7477],\n",
      "        [-0.5973],\n",
      "        [-0.4143],\n",
      "        [-0.5092]], device='cuda:0') tensor([[-0.3603],\n",
      "        [ 0.0012],\n",
      "        [ 0.2745],\n",
      "        [-0.0311],\n",
      "        [ 0.0160],\n",
      "        [-0.2084],\n",
      "        [-0.1786],\n",
      "        [-0.0482],\n",
      "        [-0.2608],\n",
      "        [-0.2261]], device='cuda:0', grad_fn=<SubBackward0>) tensor(0.4031, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Training set: Average loss: 0.496176\n",
      "Validation set: Average loss: 96.619237, Accuracy: 0/1077 (0%)\n",
      "\n",
      "983\n",
      "Epoch: 983\n",
      "tensor([[-0.6874],\n",
      "        [-2.2250],\n",
      "        [-2.2893],\n",
      "        [-0.1690],\n",
      "        [-0.7518],\n",
      "        [-1.7167],\n",
      "        [-0.6562],\n",
      "        [-1.0230],\n",
      "        [-0.4793],\n",
      "        [-0.7590]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[-0.6700],\n",
      "        [-2.1638],\n",
      "        [-2.3606],\n",
      "        [-0.2278],\n",
      "        [-0.7998],\n",
      "        [-1.5897],\n",
      "        [-0.7477],\n",
      "        [-0.5973],\n",
      "        [-0.4143],\n",
      "        [-0.5092]], device='cuda:0') tensor([[-0.0174],\n",
      "        [-0.0613],\n",
      "        [ 0.0713],\n",
      "        [ 0.0588],\n",
      "        [ 0.0480],\n",
      "        [-0.1270],\n",
      "        [ 0.0915],\n",
      "        [-0.4257],\n",
      "        [-0.0650],\n",
      "        [-0.2498]], device='cuda:0', grad_fn=<SubBackward0>) tensor(0.2873, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Training set: Average loss: 0.476592\n",
      "Validation set: Average loss: 97.556162, Accuracy: 0/1077 (0%)\n",
      "\n",
      "984\n",
      "Epoch: 984\n",
      "tensor([[-0.8220],\n",
      "        [-2.1760],\n",
      "        [-2.1922],\n",
      "        [-0.1153],\n",
      "        [-0.7649],\n",
      "        [-1.3969],\n",
      "        [-0.8594],\n",
      "        [-0.4295],\n",
      "        [-0.9185],\n",
      "        [-0.8973]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[-0.6700],\n",
      "        [-2.1638],\n",
      "        [-2.3606],\n",
      "        [-0.2278],\n",
      "        [-0.7998],\n",
      "        [-1.5897],\n",
      "        [-0.7477],\n",
      "        [-0.5973],\n",
      "        [-0.4143],\n",
      "        [-0.5092]], device='cuda:0') tensor([[-0.1519],\n",
      "        [-0.0122],\n",
      "        [ 0.1684],\n",
      "        [ 0.1125],\n",
      "        [ 0.0349],\n",
      "        [ 0.1928],\n",
      "        [-0.1116],\n",
      "        [ 0.1678],\n",
      "        [-0.5042],\n",
      "        [-0.3882]], device='cuda:0', grad_fn=<SubBackward0>) tensor(0.5481, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Training set: Average loss: 0.499875\n",
      "Validation set: Average loss: 100.925723, Accuracy: 0/1077 (0%)\n",
      "\n",
      "985\n",
      "Epoch: 985\n",
      "tensor([[-0.5767],\n",
      "        [-2.4561],\n",
      "        [-2.0525],\n",
      "        [-0.0368],\n",
      "        [-0.8709],\n",
      "        [-1.8012],\n",
      "        [-0.6932],\n",
      "        [-0.4838],\n",
      "        [-0.5601],\n",
      "        [-0.8831]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[-0.6700],\n",
      "        [-2.1638],\n",
      "        [-2.3606],\n",
      "        [-0.2278],\n",
      "        [-0.7998],\n",
      "        [-1.5897],\n",
      "        [-0.7477],\n",
      "        [-0.5973],\n",
      "        [-0.4143],\n",
      "        [-0.5092]], device='cuda:0') tensor([[ 0.0934],\n",
      "        [-0.2924],\n",
      "        [ 0.3081],\n",
      "        [ 0.1911],\n",
      "        [-0.0711],\n",
      "        [-0.2115],\n",
      "        [ 0.0545],\n",
      "        [ 0.1135],\n",
      "        [-0.1458],\n",
      "        [-0.3739]], device='cuda:0', grad_fn=<SubBackward0>) tensor(0.4523, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Training set: Average loss: 0.475317\n",
      "Validation set: Average loss: 100.974611, Accuracy: 0/1077 (0%)\n",
      "\n",
      "986\n",
      "Epoch: 986\n",
      "tensor([[-0.5869],\n",
      "        [-2.0435],\n",
      "        [-2.0876],\n",
      "        [-0.1237],\n",
      "        [-0.9591],\n",
      "        [-1.5085],\n",
      "        [-0.5937],\n",
      "        [-0.5361],\n",
      "        [-0.5939],\n",
      "        [-0.4986]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[-0.6700],\n",
      "        [-2.1638],\n",
      "        [-2.3606],\n",
      "        [-0.2278],\n",
      "        [-0.7998],\n",
      "        [-1.5897],\n",
      "        [-0.7477],\n",
      "        [-0.5973],\n",
      "        [-0.4143],\n",
      "        [-0.5092]], device='cuda:0') tensor([[ 0.0831],\n",
      "        [ 0.1203],\n",
      "        [ 0.2730],\n",
      "        [ 0.1041],\n",
      "        [-0.1593],\n",
      "        [ 0.0812],\n",
      "        [ 0.1540],\n",
      "        [ 0.0612],\n",
      "        [-0.1796],\n",
      "        [ 0.0106]], device='cuda:0', grad_fn=<SubBackward0>) tensor(0.1985, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Training set: Average loss: 0.466823\n",
      "Validation set: Average loss: 101.361951, Accuracy: 0/1077 (0%)\n",
      "\n",
      "987\n",
      "Epoch: 987\n",
      "tensor([[-0.8129],\n",
      "        [-2.0403],\n",
      "        [-2.4460],\n",
      "        [-0.0669],\n",
      "        [-0.7621],\n",
      "        [-1.5518],\n",
      "        [-0.9329],\n",
      "        [-0.4991],\n",
      "        [-0.4621],\n",
      "        [-0.4855]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[-0.6700],\n",
      "        [-2.1638],\n",
      "        [-2.3606],\n",
      "        [-0.2278],\n",
      "        [-0.7998],\n",
      "        [-1.5897],\n",
      "        [-0.7477],\n",
      "        [-0.5973],\n",
      "        [-0.4143],\n",
      "        [-0.5092]], device='cuda:0') tensor([[-0.1429],\n",
      "        [ 0.1235],\n",
      "        [-0.0854],\n",
      "        [ 0.1609],\n",
      "        [ 0.0377],\n",
      "        [ 0.0379],\n",
      "        [-0.1852],\n",
      "        [ 0.0982],\n",
      "        [-0.0478],\n",
      "        [ 0.0237]], device='cuda:0', grad_fn=<SubBackward0>) tensor(0.1185, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Training set: Average loss: 0.471591\n",
      "Validation set: Average loss: 101.703684, Accuracy: 0/1077 (0%)\n",
      "\n",
      "988\n",
      "Epoch: 988\n",
      "tensor([[-0.7327],\n",
      "        [-2.4891],\n",
      "        [-2.9715],\n",
      "        [-0.2154],\n",
      "        [-0.8873],\n",
      "        [-1.5669],\n",
      "        [-0.7121],\n",
      "        [-0.5549],\n",
      "        [-0.7124],\n",
      "        [-0.6190]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[-0.6700],\n",
      "        [-2.1638],\n",
      "        [-2.3606],\n",
      "        [-0.2278],\n",
      "        [-0.7998],\n",
      "        [-1.5897],\n",
      "        [-0.7477],\n",
      "        [-0.5973],\n",
      "        [-0.4143],\n",
      "        [-0.5092]], device='cuda:0') tensor([[-0.0626],\n",
      "        [-0.3254],\n",
      "        [-0.6109],\n",
      "        [ 0.0124],\n",
      "        [-0.0875],\n",
      "        [ 0.0228],\n",
      "        [ 0.0357],\n",
      "        [ 0.0424],\n",
      "        [-0.2981],\n",
      "        [-0.1099]], device='cuda:0', grad_fn=<SubBackward0>) tensor(0.5954, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Training set: Average loss: 0.461148\n",
      "Validation set: Average loss: 102.454361, Accuracy: 0/1077 (0%)\n",
      "\n",
      "989\n",
      "Epoch: 989\n",
      "tensor([[-0.5857],\n",
      "        [-2.3929],\n",
      "        [-2.2575],\n",
      "        [-0.2031],\n",
      "        [-0.7839],\n",
      "        [-1.9191],\n",
      "        [-0.6618],\n",
      "        [-1.1024],\n",
      "        [-0.6399],\n",
      "        [-0.5042]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[-0.6700],\n",
      "        [-2.1638],\n",
      "        [-2.3606],\n",
      "        [-0.2278],\n",
      "        [-0.7998],\n",
      "        [-1.5897],\n",
      "        [-0.7477],\n",
      "        [-0.5973],\n",
      "        [-0.4143],\n",
      "        [-0.5092]], device='cuda:0') tensor([[ 0.0843],\n",
      "        [-0.2292],\n",
      "        [ 0.1031],\n",
      "        [ 0.0247],\n",
      "        [ 0.0159],\n",
      "        [-0.3294],\n",
      "        [ 0.0859],\n",
      "        [-0.5051],\n",
      "        [-0.2256],\n",
      "        [ 0.0049]], device='cuda:0', grad_fn=<SubBackward0>) tensor(0.4930, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Training set: Average loss: 0.461131\n",
      "Validation set: Average loss: 100.392789, Accuracy: 0/1077 (0%)\n",
      "\n",
      "990\n",
      "Epoch: 990\n",
      "tensor([[-0.5966],\n",
      "        [-2.3707],\n",
      "        [-2.1578],\n",
      "        [-0.3466],\n",
      "        [-0.7474],\n",
      "        [-1.5369],\n",
      "        [-0.7142],\n",
      "        [-0.4354],\n",
      "        [-0.3759],\n",
      "        [-0.5227]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[-0.6700],\n",
      "        [-2.1638],\n",
      "        [-2.3606],\n",
      "        [-0.2278],\n",
      "        [-0.7998],\n",
      "        [-1.5897],\n",
      "        [-0.7477],\n",
      "        [-0.5973],\n",
      "        [-0.4143],\n",
      "        [-0.5092]], device='cuda:0') tensor([[ 0.0735],\n",
      "        [-0.2070],\n",
      "        [ 0.2028],\n",
      "        [-0.1188],\n",
      "        [ 0.0524],\n",
      "        [ 0.0527],\n",
      "        [ 0.0335],\n",
      "        [ 0.1619],\n",
      "        [ 0.0384],\n",
      "        [-0.0135]], device='cuda:0', grad_fn=<SubBackward0>) tensor(0.1380, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Training set: Average loss: 0.453638\n",
      "Validation set: Average loss: 101.364468, Accuracy: 0/1077 (0%)\n",
      "\n",
      "991\n",
      "Epoch: 991\n",
      "tensor([[-0.7611],\n",
      "        [-2.0404],\n",
      "        [-2.0168],\n",
      "        [-0.5393],\n",
      "        [-0.7658],\n",
      "        [-1.6212],\n",
      "        [-0.6502],\n",
      "        [-0.5100],\n",
      "        [-0.3500],\n",
      "        [-0.5363]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[-0.6700],\n",
      "        [-2.1638],\n",
      "        [-2.3606],\n",
      "        [-0.2278],\n",
      "        [-0.7998],\n",
      "        [-1.5897],\n",
      "        [-0.7477],\n",
      "        [-0.5973],\n",
      "        [-0.4143],\n",
      "        [-0.5092]], device='cuda:0') tensor([[-0.0911],\n",
      "        [ 0.1234],\n",
      "        [ 0.3438],\n",
      "        [-0.3115],\n",
      "        [ 0.0340],\n",
      "        [-0.0315],\n",
      "        [ 0.0975],\n",
      "        [ 0.0873],\n",
      "        [ 0.0643],\n",
      "        [-0.0271]], device='cuda:0', grad_fn=<SubBackward0>) tensor(0.2629, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Training set: Average loss: 0.492978\n",
      "Validation set: Average loss: 101.567134, Accuracy: 0/1077 (0%)\n",
      "\n",
      "992\n",
      "Epoch: 992\n",
      "tensor([[-0.8671],\n",
      "        [-2.2969],\n",
      "        [-2.0534],\n",
      "        [-0.3084],\n",
      "        [-0.8842],\n",
      "        [-1.4502],\n",
      "        [-0.8576],\n",
      "        [-0.4682],\n",
      "        [-0.4574],\n",
      "        [-0.5089]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[-0.6700],\n",
      "        [-2.1638],\n",
      "        [-2.3606],\n",
      "        [-0.2278],\n",
      "        [-0.7998],\n",
      "        [-1.5897],\n",
      "        [-0.7477],\n",
      "        [-0.5973],\n",
      "        [-0.4143],\n",
      "        [-0.5092]], device='cuda:0') tensor([[-0.1971],\n",
      "        [-0.1331],\n",
      "        [ 0.3072],\n",
      "        [-0.0806],\n",
      "        [-0.0844],\n",
      "        [ 0.1395],\n",
      "        [-0.1099],\n",
      "        [ 0.1291],\n",
      "        [-0.0431],\n",
      "        [ 0.0003]], device='cuda:0', grad_fn=<SubBackward0>) tensor(0.2146, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Training set: Average loss: 0.467438\n",
      "Validation set: Average loss: 100.993049, Accuracy: 0/1077 (0%)\n",
      "\n",
      "993\n",
      "Epoch: 993\n",
      "tensor([[-0.7630],\n",
      "        [-2.0332],\n",
      "        [-2.0258],\n",
      "        [-0.3369],\n",
      "        [-0.9408],\n",
      "        [-1.6252],\n",
      "        [-0.8078],\n",
      "        [-0.4746],\n",
      "        [-0.3979],\n",
      "        [-0.6335]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[-0.6700],\n",
      "        [-2.1638],\n",
      "        [-2.3606],\n",
      "        [-0.2278],\n",
      "        [-0.7998],\n",
      "        [-1.5897],\n",
      "        [-0.7477],\n",
      "        [-0.5973],\n",
      "        [-0.4143],\n",
      "        [-0.5092]], device='cuda:0') tensor([[-0.0930],\n",
      "        [ 0.1306],\n",
      "        [ 0.3348],\n",
      "        [-0.1091],\n",
      "        [-0.1410],\n",
      "        [-0.0355],\n",
      "        [-0.0601],\n",
      "        [ 0.1227],\n",
      "        [ 0.0164],\n",
      "        [-0.1244]], device='cuda:0', grad_fn=<SubBackward0>) tensor(0.2053, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Training set: Average loss: 0.477321\n",
      "Validation set: Average loss: 102.512776, Accuracy: 0/1077 (0%)\n",
      "\n",
      "994\n",
      "Epoch: 994\n",
      "tensor([[-0.6418],\n",
      "        [-1.8253],\n",
      "        [-2.5510],\n",
      "        [-0.4295],\n",
      "        [-0.7015],\n",
      "        [-1.4114],\n",
      "        [-0.7149],\n",
      "        [-0.6596],\n",
      "        [-0.6655],\n",
      "        [-0.7068]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[-0.6700],\n",
      "        [-2.1638],\n",
      "        [-2.3606],\n",
      "        [-0.2278],\n",
      "        [-0.7998],\n",
      "        [-1.5897],\n",
      "        [-0.7477],\n",
      "        [-0.5973],\n",
      "        [-0.4143],\n",
      "        [-0.5092]], device='cuda:0') tensor([[ 0.0282],\n",
      "        [ 0.3384],\n",
      "        [-0.1905],\n",
      "        [-0.2017],\n",
      "        [ 0.0983],\n",
      "        [ 0.1783],\n",
      "        [ 0.0328],\n",
      "        [-0.0623],\n",
      "        [-0.2512],\n",
      "        [-0.1977]], device='cuda:0', grad_fn=<SubBackward0>) tensor(0.3408, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Training set: Average loss: 0.454683\n",
      "Validation set: Average loss: 102.812254, Accuracy: 0/1077 (0%)\n",
      "\n",
      "995\n",
      "Epoch: 995\n",
      "tensor([[-0.7667],\n",
      "        [-2.0649],\n",
      "        [-2.6489],\n",
      "        [-0.5157],\n",
      "        [-1.1022],\n",
      "        [-1.7919],\n",
      "        [-0.7235],\n",
      "        [-0.5083],\n",
      "        [-0.7603],\n",
      "        [-0.6828]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[-0.6700],\n",
      "        [-2.1638],\n",
      "        [-2.3606],\n",
      "        [-0.2278],\n",
      "        [-0.7998],\n",
      "        [-1.5897],\n",
      "        [-0.7477],\n",
      "        [-0.5973],\n",
      "        [-0.4143],\n",
      "        [-0.5092]], device='cuda:0') tensor([[-0.0966],\n",
      "        [ 0.0989],\n",
      "        [-0.2883],\n",
      "        [-0.2878],\n",
      "        [-0.3024],\n",
      "        [-0.2022],\n",
      "        [ 0.0242],\n",
      "        [ 0.0890],\n",
      "        [-0.3460],\n",
      "        [-0.1737]], device='cuda:0', grad_fn=<SubBackward0>) tensor(0.4758, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Training set: Average loss: 0.499927\n",
      "Validation set: Average loss: 103.337766, Accuracy: 0/1077 (0%)\n",
      "\n",
      "996\n",
      "Epoch: 996\n",
      "tensor([[-0.6609],\n",
      "        [-2.3653],\n",
      "        [-2.2913],\n",
      "        [-0.0244],\n",
      "        [-0.7090],\n",
      "        [-1.4889],\n",
      "        [-0.7471],\n",
      "        [-0.4861],\n",
      "        [-0.6621],\n",
      "        [-0.4591]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[-0.6700],\n",
      "        [-2.1638],\n",
      "        [-2.3606],\n",
      "        [-0.2278],\n",
      "        [-0.7998],\n",
      "        [-1.5897],\n",
      "        [-0.7477],\n",
      "        [-0.5973],\n",
      "        [-0.4143],\n",
      "        [-0.5092]], device='cuda:0') tensor([[ 0.0091],\n",
      "        [-0.2015],\n",
      "        [ 0.0693],\n",
      "        [ 0.2034],\n",
      "        [ 0.0908],\n",
      "        [ 0.1007],\n",
      "        [ 0.0007],\n",
      "        [ 0.1112],\n",
      "        [-0.2478],\n",
      "        [ 0.0501]], device='cuda:0', grad_fn=<SubBackward0>) tensor(0.1815, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Training set: Average loss: 0.495596\n",
      "Validation set: Average loss: 102.443740, Accuracy: 0/1077 (0%)\n",
      "\n",
      "997\n",
      "Epoch: 997\n",
      "tensor([[-0.6331],\n",
      "        [-2.0168],\n",
      "        [-2.4513],\n",
      "        [-0.0276],\n",
      "        [-0.7349],\n",
      "        [-1.4058],\n",
      "        [-0.9546],\n",
      "        [-0.7975],\n",
      "        [-0.4664],\n",
      "        [-0.6982]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[-0.6700],\n",
      "        [-2.1638],\n",
      "        [-2.3606],\n",
      "        [-0.2278],\n",
      "        [-0.7998],\n",
      "        [-1.5897],\n",
      "        [-0.7477],\n",
      "        [-0.5973],\n",
      "        [-0.4143],\n",
      "        [-0.5092]], device='cuda:0') tensor([[ 0.0369],\n",
      "        [ 0.1469],\n",
      "        [-0.0907],\n",
      "        [ 0.2002],\n",
      "        [ 0.0649],\n",
      "        [ 0.1839],\n",
      "        [-0.2068],\n",
      "        [-0.2002],\n",
      "        [-0.0521],\n",
      "        [-0.1890]], device='cuda:0', grad_fn=<SubBackward0>) tensor(0.2306, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Training set: Average loss: 0.497608\n",
      "Validation set: Average loss: 100.497219, Accuracy: 0/1077 (0%)\n",
      "\n",
      "998\n",
      "Epoch: 998\n",
      "tensor([[-0.6504],\n",
      "        [-1.7368],\n",
      "        [-2.4110],\n",
      "        [-0.0282],\n",
      "        [-0.6487],\n",
      "        [-1.5332],\n",
      "        [-0.7298],\n",
      "        [-0.6584],\n",
      "        [-0.6267],\n",
      "        [-0.8072]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[-0.6700],\n",
      "        [-2.1638],\n",
      "        [-2.3606],\n",
      "        [-0.2278],\n",
      "        [-0.7998],\n",
      "        [-1.5897],\n",
      "        [-0.7477],\n",
      "        [-0.5973],\n",
      "        [-0.4143],\n",
      "        [-0.5092]], device='cuda:0') tensor([[ 0.0196],\n",
      "        [ 0.4270],\n",
      "        [-0.0504],\n",
      "        [ 0.1996],\n",
      "        [ 0.1511],\n",
      "        [ 0.0564],\n",
      "        [ 0.0180],\n",
      "        [-0.0611],\n",
      "        [-0.2124],\n",
      "        [-0.2980]], device='cuda:0', grad_fn=<SubBackward0>) tensor(0.3891, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Training set: Average loss: 0.461867\n",
      "Validation set: Average loss: 100.082829, Accuracy: 0/1077 (0%)\n",
      "\n",
      "999\n",
      "Epoch: 999\n",
      "tensor([[-0.9943],\n",
      "        [-2.4321],\n",
      "        [-2.2816],\n",
      "        [-0.5442],\n",
      "        [-0.8075],\n",
      "        [-1.2112],\n",
      "        [-0.7030],\n",
      "        [-0.7700],\n",
      "        [-0.4812],\n",
      "        [-0.6472]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[-0.6700],\n",
      "        [-2.1638],\n",
      "        [-2.3606],\n",
      "        [-0.2278],\n",
      "        [-0.7998],\n",
      "        [-1.5897],\n",
      "        [-0.7477],\n",
      "        [-0.5973],\n",
      "        [-0.4143],\n",
      "        [-0.5092]], device='cuda:0') tensor([[-0.3242],\n",
      "        [-0.2684],\n",
      "        [ 0.0790],\n",
      "        [-0.3164],\n",
      "        [-0.0077],\n",
      "        [ 0.3785],\n",
      "        [ 0.0447],\n",
      "        [-0.1727],\n",
      "        [-0.0669],\n",
      "        [-0.1380]], device='cuda:0', grad_fn=<SubBackward0>) tensor(0.4821, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Training set: Average loss: 0.454394\n",
      "Validation set: Average loss: 98.146453, Accuracy: 0/1077 (0%)\n",
      "\n",
      "1000\n",
      "Epoch: 1000\n",
      "tensor([[-0.7904],\n",
      "        [-2.0699],\n",
      "        [-2.6034],\n",
      "        [-0.3561],\n",
      "        [-0.8194],\n",
      "        [-1.3654],\n",
      "        [-0.6173],\n",
      "        [-0.8775],\n",
      "        [-0.6143],\n",
      "        [-0.4897]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[-0.6700],\n",
      "        [-2.1638],\n",
      "        [-2.3606],\n",
      "        [-0.2278],\n",
      "        [-0.7998],\n",
      "        [-1.5897],\n",
      "        [-0.7477],\n",
      "        [-0.5973],\n",
      "        [-0.4143],\n",
      "        [-0.5092]], device='cuda:0') tensor([[-0.1203],\n",
      "        [ 0.0939],\n",
      "        [-0.2429],\n",
      "        [-0.1283],\n",
      "        [-0.0196],\n",
      "        [ 0.2243],\n",
      "        [ 0.1304],\n",
      "        [-0.2802],\n",
      "        [-0.2000],\n",
      "        [ 0.0195]], device='cuda:0', grad_fn=<SubBackward0>) tensor(0.2853, device='cuda:0', grad_fn=<MseLossBackward>)\n",
      "Training set: Average loss: 0.488256\n",
      "Validation set: Average loss: 98.050522, Accuracy: 0/1077 (0%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use an \"Adam\" optimizer to adjust weights\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Specify the loss criteria\n",
    "loss_criteria = nn.MSELoss(reduction='sum')\n",
    "\n",
    "# Track metrics in these arrays\n",
    "epoch_nums = []\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "\n",
    "\n",
    "# Train over 10 epochs (We restrict to 10 for time issues)\n",
    "epochs = 1000\n",
    "print('Training on', device)\n",
    "for epoch in range(1, epochs + 1):\n",
    "        print(epoch)\n",
    "        train_loss = train(model, device, train_loader, optimizer, epoch)\n",
    "        test_loss = test(model, device, test_loader)\n",
    "        epoch_nums.append(epoch)\n",
    "        training_loss.append(train_loss)\n",
    "        validation_loss.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mMore than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\u001b[0m \u001b[0;36m(RuntimeWarning)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib qt\n",
    "#Loop that pulls a different image each time and cycles through the images in the dataloader \n",
    "for (picture,label) in test_loader:\n",
    "    plt.figure()\n",
    "    plt.imshow(picture[0][0,0:,0:])\n",
    "    plt.show()\n",
    "\n",
    "#Loop we used in the meeting that generates the same image over and over, I think because its pulling the same data loader entry\n",
    "counter=0\n",
    "for i in test_loader:\n",
    "    while counter < 10:\n",
    "        plt.figure()\n",
    "        plt.imshow(i[0][0][0,0:,0:])\n",
    "        plt.show()\n",
    "        counter=counter+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mMore than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\u001b[0m \u001b[0;36m(RuntimeWarning)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "for (picture,label) in test_loader:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(picture[0][0,0:,0:])\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(picture[1][0,0:,0:])\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(picture[2][0,0:,0:])\n",
    "    plt.show()\n",
    "    # while counter <3:\n",
    "    # plt.figure()\n",
    "    # print(np.amax(picture[0][0,0:,0:].cpu().detach().numpy()))\n",
    "    # print(np.amin(picture[0][0,0:,0:].cpu().detach().numpy()))\n",
    "    # plt.imshow(picture[0][0,0:,0:])\n",
    "    # plt.colorbar()\n",
    "    # plt.show()\n",
    "    # counter=counter+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n",
      "tensor([[-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225],\n",
      "        [-1.5225]], device='cuda:0', grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in test_loader:\n",
    "    # print(i[1].shape)\n",
    "    print(model(i[0].to(device))[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.plot(epoch_nums, np.log10(training_loss))\n",
    "plt.plot(epoch_nums, np.log10(validation_loss))\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Log of loss')\n",
    "plt.legend(['training', 'validation'], loc='upper right')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Confusion matrix, Not relevant in a linear regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting predictions from test set...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of continuous and binary targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7437220421c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Plot the confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruelabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mtick_marks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \"\"\"\n\u001b[0;32m--> 268\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0;32m---> 90\u001b[0;31m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of continuous and binary targets"
     ]
    }
   ],
   "source": [
    "# Defining Labels and Predictions\n",
    "truelabels = []\n",
    "predictions = []\n",
    "model.eval()\n",
    "model.cuda\n",
    "print(\"Getting predictions from test set...\")\n",
    "for data, target in test_loader:\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    for label in target.cpu().detach().numpy():\n",
    "        truelabels.append(label)\n",
    "    for prediction in model(data).cpu().detach().numpy().argmax(1):\n",
    "        predictions.append(prediction) \n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(truelabels, predictions)\n",
    "tick_marks = np.arange(len(classes))\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = classes, columns = classes)\n",
    "plt.figure(figsize = (7,7))\n",
    "sns.heatmap(df_cm, annot=True, cmap=plt.cm.Blues, fmt='g')\n",
    "plt.xlabel(\"Predicted Shape\", fontsize = 20)\n",
    "plt.ylabel(\"True Shape\", fontsize = 20)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "332de2e570cd2f6fcfd1dc3718047bca654fabf3a28e9f4985b0d5046bfd1195"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "metadata": {
   "interpreter": {
    "hash": "332de2e570cd2f6fcfd1dc3718047bca654fabf3a28e9f4985b0d5046bfd1195"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
