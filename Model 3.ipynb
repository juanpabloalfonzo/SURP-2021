{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python376jvsc74a57bd0332de2e570cd2f6fcfd1dc3718047bca654fabf3a28e9f4985b0d5046bfd1195",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "332de2e570cd2f6fcfd1dc3718047bca654fabf3a28e9f4985b0d5046bfd1195"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Model 3: Predict Star Formation Variables (sSFR, SFR, M*, age) Based on Visual Morphology (galaxy image)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mpath /home/juanp/sas/dr15/manga/spectro/analysis/v2_4_3/2.2.1/dapall-v2_4_3-2.2.1.fits cannot be found. Setting dapall to None.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Loading needed modules and classes/functions \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "from torchvision.datasets import ImageFolder \n",
    "from torchvision.io import read_image\n",
    "from torchvision.io import decode_image\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import marvin\n",
    "from marvin.tools.maps import Maps\n",
    "from marvin.tools.image import Image\n",
    "from marvin.utils.general.images import get_images_by_list\n",
    "from marvin import config\n",
    "from marvin.tools.cube import Cube\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image as image_PIL\n",
    "\n",
    "#set config attributes and turn on global downloads of Marvin data\n",
    "config.setRelease('DR15')\n",
    "config.mode = 'local'\n",
    "config.download = True\n",
    "\n",
    "#3 Linear layers NN, 1 hidden \n",
    "class linearRegression(torch.nn.Module):\n",
    "    def __init__(self, inputSize, outputSize):\n",
    "        super(linearRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(inputSize, outputSize)\n",
    "        self.linear1 = torch.nn.Linear(outputSize, outputSize)\n",
    "        self.ReLU= torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.ReLU(x)\n",
    "        x = self.linear1(x)\n",
    "        return x\n"
   ]
  },
  {
   "source": [
    "# Importing Data from Schema Table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data=pd.read_csv('CompleteTable.csv')  #Importing All MaNGA Data from DPRall Schema\n",
    "\n",
    "galaxy_list=np.loadtxt('Query Results',dtype=str) #Pulling Manga ID's of galaxies which satisfy log(M) > 9 and 0 < z < 0.1\n",
    "\n",
    "galaxy_index=np.zeros(len(galaxy_list)) \n",
    "for i in range (len(galaxy_list)): #Getting the index of these galaxies in the schema table\n",
    "    galaxy_index[i]=np.where(data.loc[:,'mangaid']==galaxy_list[i])[0][0]\n",
    "\n",
    "galaxy_index=np.array(galaxy_index,dtype=int) #Ensuring we have array that can be used to index, force int \n",
    "\n",
    "galaxies=data.iloc[galaxy_index] #DF of galaxies which satisfies the condition, contains all relevant schema data \n",
    "\n",
    "#Problem with image associated with manga id at galaxy_list[3548], mangaid- 1-135668\n",
    "galaxy_list=np.delete(galaxy_list,3548)\n",
    "\n",
    "#Creating the arrays of the independent variables were are interested in, and dependent variable n \n",
    "\n",
    "mass=galaxies.loc[:,'nsa_sersic_mass']\n",
    "log_mass=np.log10(mass)\n",
    "\n",
    "SFR=galaxies.loc[:,'sfr_tot']\n",
    "log_SFR=np.log10(SFR)\n",
    "\n",
    "ha_flux=galaxies.loc[:,'emline_gflux_tot_ha_6564']\n",
    "\n",
    "n=galaxies.loc[:,'nsa_sersic_n']\n",
    "n=np.array(n,dtype=np.float32)\n",
    "n=torch.from_numpy(n).to('cuda:0').reshape(-1,1)\n"
   ]
  },
  {
   "source": [
    "# Importing Images from their Downloaded Locations \n"
   ],
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mSpecified hdu=MANGA not found, reading in first available table (hdu=1) instead. This will result in an error in future versions!\u001b[0m \u001b[0;36m(AstropyDeprecationWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-210186. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-209770. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-209772. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-209786. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-209823. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-235398. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-235530. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-592881. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-569225. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-548221. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-149686. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-137801. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-137845. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-137853. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-166932. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-166919. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-166754. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-113469. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-635503. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-113375. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-113525. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-277161. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-277159. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-277691. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-277154. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-277103. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-587938. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-255691. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-255959. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-256104. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-278485. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-277858. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-558910. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-256457. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-256456. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-256048. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-456757. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-258311. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-178443. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-178473. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-561017. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-177250. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-177236. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-211017. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-210604. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n",
      "\u001b[1;33m[WARNING]: \u001b[0m\u001b[0;39mmore than one plate-ifu found for mangaid=1-210611. Using the one with the highest SN2.\u001b[0m \u001b[0;36m(MarvinUserWarning)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "image_locations=[]\n",
    "for i in range (len(galaxy_list)):\n",
    "    image_locations.append(Image(galaxy_list[i]).filename)\n",
    "    \n",
    "image_locations=np.array(image_locations,dtype=str)\n",
    "np.savetxt('Image Directories',image_locations,fmt='%s')\n",
    "\n",
    "image_locations=np.loadtxt('Image Directories',dtype=str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8934/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9870/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8552/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9493/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8311/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8261/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9512/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9486/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8937/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8134/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8485/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9048/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9488/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/7991/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8140/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8613/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8931/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9891/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9024/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/7957/stack/images\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/7957/stack/manga-7957-12703-LOGCUBE.fits.gz\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9888/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8991/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8256/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8081/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9038/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8444/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8550/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8454/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8144/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8243/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8990/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8158/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8993/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8549/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9047/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8483/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9185/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8566/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8462/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9505/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/7992/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8156/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9033/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9044/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8623/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8615/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9025/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8082/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9036/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8712/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8331/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9041/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8949/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8309/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9039/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8446/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9872/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/7964/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8141/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9088/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8728/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8323/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8946/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9193/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8716/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8318/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8077/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8996/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8150/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8588/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9487/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9085/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9876/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8146/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8257/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8480/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8445/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9501/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8553/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9881/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8247/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8464/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8978/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8727/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8592/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8330/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8983/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8131/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8601/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/7960/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8484/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8713/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8717/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8939/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9869/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8322/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8449/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/7975/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8447/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8440/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8329/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8315/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8333/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9042/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/7962/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8254/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8626/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8936/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8982/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8147/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8138/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8616/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8452/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8618/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8241/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8555/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8482/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8943/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8602/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9494/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8725/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8080/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8153/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8714/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8143/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9194/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9883/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8461/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8999/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8455/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8084/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/7815/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8149/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9510/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8145/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8715/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8481/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8940/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9034/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8935/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9035/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8600/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9049/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8548/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9868/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9490/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8258/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8720/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9182/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/7972/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8603/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8132/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9196/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/7958/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8547/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8948/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9045/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8726/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8262/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9031/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8443/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9491/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8332/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8313/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9485/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9497/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9095/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9871/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9183/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8597/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/7495/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/9043/stack/images\n",
      "processing folder images\n",
      "processing folder stack\n",
      "/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/8611/stack/images\n",
      "processing folder images\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# function to resize image\n",
    "def resize_image(src_image, size=(128,128), bg_color=\"white\"): \n",
    "    from PIL import Image, ImageOps \n",
    "    \n",
    "    # resize the image so the longest dimension matches our target size\n",
    "    src_image.thumbnail(size, Image.ANTIALIAS)\n",
    "    \n",
    "    # Create a new square background image\n",
    "    new_image = Image.new(\"RGB\", size, bg_color)\n",
    "    \n",
    "    # Paste the resized image into the center of the square background\n",
    "    new_image.paste(src_image, (int((size[0] - src_image.size[0]) / 2), int((size[1] - src_image.size[1]) / 2)))\n",
    "  \n",
    "    # return the resized image\n",
    "    return new_image\n",
    "\n",
    "\n",
    "\n",
    "training_folder_name = '/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/'\n",
    "\n",
    "# New location for the resized images\n",
    "train_folder = '/home/juanp/Documents/Resized MaNGA Pictures'\n",
    "\n",
    "\n",
    "# Create resized copies of all of the source images\n",
    "size = (128,128)\n",
    "\n",
    "# Create the output folder if it doesn't already exist\n",
    "if os.path.exists(train_folder):\n",
    "    shutil.rmtree(train_folder)\n",
    "\n",
    "# Loop through each subfolder in the input folder\n",
    "print('Transforming images...')\n",
    "for root, folders, files in os.walk(training_folder_name):\n",
    "    for sub_folder in folders:\n",
    "        print('processing folder ' + sub_folder)\n",
    "        # Create a matching subfolder in the output dir\n",
    "        saveFolder = os.path.join(train_folder,sub_folder)\n",
    "        if not os.path.exists(saveFolder):\n",
    "            os.makedirs(saveFolder)\n",
    "        # Loop through the files in the subfolder\n",
    "        file_names = os.listdir(os.path.join(root,sub_folder))\n",
    "        for file_name in file_names:\n",
    "            # Open the file\n",
    "            file_path = os.path.join(root,sub_folder, file_name)\n",
    "            #print(\"reading \" + file_path)\n",
    "            try:\n",
    "                image = image_PIL.open(file_path)\n",
    "                 # Create a resized version and save it\n",
    "                resized_image = resize_image(image, size)\n",
    "                saveAs = os.path.join(saveFolder, file_name)\n",
    "                #print(\"writing \" + saveAs)\n",
    "                resized_image.save(saveAs)\n",
    "            except:\n",
    "                print(file_path)\n",
    "           \n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "source": [
    "# Putting the Images into DataLoaders"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(tensor([[[-0.7020, -1.0000, -0.8902,  ..., -0.9451, -0.9608, -0.9686],\n         [-0.7569, -0.9843, -0.8588,  ..., -0.9294, -0.8588, -0.8118],\n         [-0.9843, -0.9451, -0.9137,  ..., -0.8902, -0.7412, -0.5608],\n         ...,\n         [-0.9451, -0.9608, -0.9765,  ..., -0.9686, -0.9608, -0.9608],\n         [-0.8039, -1.0000, -0.9373,  ..., -0.9529, -0.9843, -1.0000],\n         [-0.4745, -0.7490, -0.9137,  ..., -0.9529, -0.8118, -0.7098]],\n\n        [[-0.5059, -0.9529, -0.8980,  ..., -0.9922, -0.9529, -0.8510],\n         [-0.6627, -0.9765, -0.9137,  ..., -1.0000, -0.9843, -0.8667],\n         [-0.9686, -0.9373, -0.9216,  ..., -0.9529, -0.8667, -0.7333],\n         ...,\n         [-0.9529, -0.9686, -1.0000,  ..., -1.0000, -0.9922, -0.9843],\n         [-0.7255, -1.0000, -1.0000,  ..., -0.9843, -1.0000, -1.0000],\n         [-0.2392, -0.6706, -0.9451,  ..., -0.9765, -0.7725, -0.5451]],\n\n        [[-0.6941, -1.0000, -0.9294,  ..., -0.9843, -0.9922, -0.9922],\n         [-0.7569, -0.9922, -0.8824,  ..., -1.0000, -0.9922, -0.9765],\n         [-1.0000, -0.9373, -0.9059,  ..., -1.0000, -1.0000, -0.9373],\n         ...,\n         [-0.9843, -0.9686, -0.9843,  ..., -1.0000, -0.9922, -0.9922],\n         [-0.8118, -1.0000, -0.9608,  ..., -0.9922, -1.0000, -1.0000],\n         [-0.4824, -0.7490, -0.9451,  ..., -0.9843, -0.8353, -0.7176]]]), 0), (tensor([[[-0.6941, -0.9922, -0.9294,  ..., -0.9451, -0.9608, -0.9922],\n         [-0.6941, -0.9451, -0.9373,  ..., -0.9294, -0.8902, -0.9373],\n         [-0.9216, -0.9373, -0.9686,  ..., -0.9294, -0.8902, -0.9059],\n         ...,\n         [-0.9686, -0.9059, -0.9137,  ..., -0.9294, -0.9451, -0.9451],\n         [-0.7961, -1.0000, -0.9373,  ..., -0.9451, -0.9765, -1.0000],\n         [-0.4745, -0.7490, -0.9137,  ..., -0.9686, -0.8118, -0.7020]],\n\n        [[-0.4824, -0.9686, -0.9529,  ..., -0.9922, -0.9608, -0.8902],\n         [-0.6549, -0.9843, -0.9843,  ..., -1.0000, -1.0000, -0.9451],\n         [-0.9608, -0.9608, -0.9922,  ..., -1.0000, -0.9843, -0.9608],\n         ...,\n         [-0.9294, -0.9137, -0.9294,  ..., -0.9608, -0.9686, -0.9843],\n         [-0.7333, -1.0000, -0.9922,  ..., -0.9765, -1.0000, -1.0000],\n         [-0.2471, -0.6627, -0.9373,  ..., -0.9922, -0.7804, -0.5216]],\n\n        [[-0.7020, -1.0000, -0.9294,  ..., -0.9843, -0.9843, -1.0000],\n         [-0.7098, -0.9451, -0.8980,  ..., -0.9686, -0.9137, -0.9294],\n         [-0.8745, -0.9059, -0.9294,  ..., -0.9686, -0.9216, -0.9059],\n         ...,\n         [-0.9922, -0.9294, -0.9373,  ..., -0.9529, -0.9686, -0.9765],\n         [-0.8196, -1.0000, -0.9765,  ..., -0.9686, -1.0000, -1.0000],\n         [-0.4902, -0.7569, -0.9529,  ..., -0.9843, -0.8275, -0.7098]]]), 1), (tensor([[[-0.7098, -1.0000, -0.9059,  ..., -0.2627, -0.3490, -0.6314],\n         [-0.7490, -0.9686, -0.9137,  ..., -0.4353, -0.4745, -0.6706],\n         [-0.9608, -0.9529, -0.9608,  ..., -0.6392, -0.6863, -0.7569],\n         ...,\n         [-0.9059, -0.8745, -0.9059,  ..., -0.9686, -0.9451, -0.8902],\n         [-0.7569, -0.9686, -0.9216,  ..., -0.9608, -0.9529, -0.9608],\n         [-0.4667, -0.7333, -0.9137,  ..., -0.9686, -0.7725, -0.6784]],\n\n        [[-0.4902, -0.9451, -0.9216,  ..., -0.5294, -0.5373, -0.5373],\n         [-0.6235, -0.9529, -0.9608,  ..., -0.7020, -0.7647, -0.7804],\n         [-0.9137, -0.9137, -0.9373,  ..., -0.8196, -0.8667, -0.9451],\n         ...,\n         [-0.9137, -0.9216, -0.9686,  ..., -0.9294, -0.9059, -0.8745],\n         [-0.6471, -0.9922, -0.9608,  ..., -0.8980, -0.9137, -0.8745],\n         [-0.1843, -0.6078, -0.8902,  ..., -0.8902, -0.6706, -0.4196]],\n\n        [[-0.7020, -1.0000, -0.9451,  ..., -0.7333, -0.7569, -0.8745],\n         [-0.7412, -0.9686, -0.9294,  ..., -0.8353, -0.8431, -0.9216],\n         [-0.9765, -0.9294, -0.9373,  ..., -0.9059, -0.8824, -0.9059],\n         ...,\n         [-0.9922, -0.9843, -1.0000,  ..., -0.9686, -0.9686, -0.9373],\n         [-0.7961, -1.0000, -0.9765,  ..., -0.9451, -0.9686, -0.9843],\n         [-0.4824, -0.7569, -0.9373,  ..., -0.9451, -0.7882, -0.6941]]]), 2), (tensor([[[-0.7020, -1.0000, -0.9608,  ..., -0.9922, -0.9922, -1.0000],\n         [-0.7490, -1.0000, -0.9686,  ..., -0.9529, -0.9529, -0.9765],\n         [-0.9686, -0.9843, -0.9922,  ..., -0.9294, -0.9608, -0.9843],\n         ...,\n         [-0.9765, -0.9529, -0.9373,  ..., -0.9529, -0.9686, -0.9608],\n         [-0.8118, -1.0000, -0.9216,  ..., -0.9608, -0.9843, -1.0000],\n         [-0.4824, -0.7412, -0.9059,  ..., -0.9843, -0.8118, -0.7098]],\n\n        [[-0.4824, -0.9529, -0.9294,  ..., -0.9922, -0.9529, -0.8745],\n         [-0.6549, -0.9922, -0.9765,  ..., -0.9765, -0.9922, -0.9529],\n         [-0.9843, -0.9922, -0.9922,  ..., -0.9451, -0.9765, -0.9765],\n         ...,\n         [-0.9373, -0.9451, -0.9451,  ..., -0.9765, -0.9843, -0.9765],\n         [-0.7098, -1.0000, -0.9451,  ..., -0.9765, -1.0000, -1.0000],\n         [-0.2157, -0.6157, -0.8745,  ..., -0.9843, -0.7647, -0.5294]],\n\n        [[-0.7020, -1.0000, -0.9529,  ..., -0.8902, -0.9373, -0.9922],\n         [-0.7490, -0.9922, -0.9451,  ..., -0.8745, -0.8745, -0.9451],\n         [-0.9843, -0.9608, -0.9843,  ..., -0.8667, -0.8980, -0.9608],\n         ...,\n         [-0.9843, -0.9765, -0.9529,  ..., -0.9373, -0.9451, -0.9451],\n         [-0.8118, -1.0000, -0.9765,  ..., -0.9373, -0.9608, -1.0000],\n         [-0.4745, -0.7490, -0.9529,  ..., -0.9608, -0.7961, -0.7020]]]), 3), (tensor([[[-0.9922, -0.9922, -0.9922,  ..., -0.7725, -0.9059, -0.6863],\n         [-0.9765, -0.9686, -0.9843,  ..., -0.7098, -0.7882, -0.6392],\n         [-0.9922, -0.9843, -0.9922,  ..., -0.6941, -0.7098, -0.7882],\n         ...,\n         [-0.0510, -0.1216, -0.1529,  ..., -0.5059, -0.5137, -0.5608],\n         [-0.1294, -0.0980, -0.1294,  ..., -0.4510, -0.5843, -0.4588],\n         [-0.0980, -0.0588, -0.1137,  ..., -0.4196, -0.4196, -0.2863]],\n\n        [[-0.8118, -0.8745, -0.8824,  ..., -0.8118, -0.8431, -0.4353],\n         [-0.9137, -0.9529, -0.9216,  ..., -0.7490, -0.8039, -0.5686],\n         [-0.9765, -0.9686, -0.9451,  ..., -0.7020, -0.7020, -0.7804],\n         ...,\n         [-0.6471, -0.6863, -0.7098,  ..., -0.7255, -0.7412, -0.7490],\n         [-0.6392, -0.7255, -0.7020,  ..., -0.6784, -0.7804, -0.5294],\n         [-0.2627, -0.5294, -0.7098,  ..., -0.6235, -0.4353, -0.0902]],\n\n        [[-0.9843, -0.9765, -0.9373,  ..., -0.8196, -0.9529, -0.7020],\n         [-0.9765, -0.9529, -0.9529,  ..., -0.7569, -0.8667, -0.6941],\n         [-0.9922, -0.9922, -0.9922,  ..., -0.8039, -0.8196, -0.8431],\n         ...,\n         [-0.6941, -0.7098, -0.6941,  ..., -0.9216, -0.9686, -0.9922],\n         [-0.7333, -0.7255, -0.6941,  ..., -0.9216, -1.0000, -0.8353],\n         [-0.5373, -0.6078, -0.6784,  ..., -0.8902, -0.7804, -0.5216]]]), 4), (tensor([[[-0.6863, -1.0000, -0.9373,  ..., -0.9529, -0.9686, -0.9843],\n         [-0.7255, -0.9922, -0.9608,  ..., -0.9608, -0.9451, -0.9529],\n         [-0.9765, -0.9608, -0.9608,  ..., -0.9529, -0.9608, -0.9608],\n         ...,\n         [-0.9451, -0.9059, -0.9294,  ..., -0.9529, -0.9059, -0.8745],\n         [-0.7725, -0.9686, -0.9059,  ..., -0.9608, -0.9529, -0.9843],\n         [-0.4745, -0.7333, -0.8980,  ..., -0.9765, -0.8039, -0.6941]],\n\n        [[-0.5137, -0.9608, -0.9451,  ..., -0.9608, -0.9294, -0.8588],\n         [-0.6627, -0.9922, -0.9686,  ..., -0.9765, -0.9922, -0.9294],\n         [-0.9137, -0.9608, -0.9529,  ..., -0.9451, -0.9608, -0.9608],\n         ...,\n         [-0.8510, -0.8824, -0.9373,  ..., -0.9765, -0.9765, -0.9765],\n         [-0.6471, -0.9843, -0.9529,  ..., -0.9608, -1.0000, -1.0000],\n         [-0.2000, -0.6392, -0.9137,  ..., -0.9608, -0.7569, -0.5373]],\n\n        [[-0.6941, -1.0000, -0.9216,  ..., -0.9922, -0.9922, -1.0000],\n         [-0.7333, -0.9843, -0.9137,  ..., -0.9843, -0.9686, -0.9686],\n         [-0.9451, -0.9294, -0.9451,  ..., -0.9686, -0.9765, -0.9686],\n         ...,\n         [-0.9686, -0.9373, -0.9686,  ..., -0.9843, -0.9686, -0.9608],\n         [-0.7961, -1.0000, -0.9608,  ..., -0.9843, -1.0000, -1.0000],\n         [-0.4824, -0.7569, -0.9451,  ..., -0.9765, -0.8275, -0.7176]]]), 5), (tensor([[[-0.7176, -0.8353, -0.9922,  ..., -0.9451, -0.7569, -0.4824],\n         [-1.0000, -1.0000, -0.9922,  ..., -0.9765, -1.0000, -0.8118],\n         [-0.9686, -0.9922, -0.9922,  ..., -1.0000, -0.9843, -1.0000],\n         ...,\n         [-0.9843, -0.9843, -1.0000,  ..., -0.8902, -0.9059, -0.9137],\n         [-0.9686, -0.9608, -0.9608,  ..., -0.8667, -0.9373, -0.7020],\n         [-0.9843, -0.9686, -0.9451,  ..., -0.8588, -0.9843, -0.6941]],\n\n        [[-0.5451, -0.7882, -1.0000,  ..., -0.9216, -0.6627, -0.2471],\n         [-1.0000, -1.0000, -1.0000,  ..., -1.0000, -1.0000, -0.7255],\n         [-0.9765, -0.9922, -0.9922,  ..., -1.0000, -0.9843, -0.9765],\n         ...,\n         [-0.9843, -0.9922, -0.9686,  ..., -1.0000, -0.9843, -0.9843],\n         [-0.9529, -0.9922, -0.9608,  ..., -0.9608, -0.9922, -0.6941],\n         [-0.8588, -0.9294, -0.9294,  ..., -0.9294, -0.9686, -0.5059]],\n\n        [[-0.7020, -0.8039, -0.9686,  ..., -0.9294, -0.7490, -0.4824],\n         [-1.0000, -0.9843, -0.9608,  ..., -0.9529, -1.0000, -0.8118],\n         [-0.9529, -0.9843, -0.9843,  ..., -0.9765, -0.9686, -1.0000],\n         ...,\n         [-0.9843, -0.9843, -1.0000,  ..., -0.9294, -0.9451, -0.9843],\n         [-0.9765, -0.9686, -0.9843,  ..., -0.8980, -0.9843, -0.7412],\n         [-0.9922, -0.9922, -0.9765,  ..., -0.9294, -1.0000, -0.6863]]]), 6), (tensor([[[-0.9922, -0.9765, -0.9843,  ..., -0.9529, -1.0000, -0.7098],\n         [-0.9294, -0.9373, -0.9843,  ..., -0.9529, -0.9843, -0.7176],\n         [-0.9216, -0.9608, -0.9843,  ..., -0.9608, -0.9451, -0.9529],\n         ...,\n         [-0.9059, -0.8588, -0.7882,  ..., -0.9843, -0.9686, -0.9686],\n         [-0.9765, -0.8902, -0.7961,  ..., -0.9529, -1.0000, -0.8039],\n         [-0.6941, -0.7490, -0.8588,  ..., -0.9216, -0.7412, -0.4745]],\n\n        [[-0.8745, -0.9529, -0.9843,  ..., -0.9529, -0.9686, -0.4902],\n         [-0.9373, -1.0000, -1.0000,  ..., -0.9608, -0.9843, -0.6549],\n         [-0.9922, -1.0000, -1.0000,  ..., -0.9451, -0.9373, -0.9529],\n         ...,\n         [-0.9843, -0.9529, -0.9216,  ..., -1.0000, -0.9765, -0.9373],\n         [-1.0000, -1.0000, -0.9294,  ..., -1.0000, -1.0000, -0.7333],\n         [-0.5373, -0.7725, -0.9843,  ..., -0.9451, -0.6706, -0.2549]],\n\n        [[-1.0000, -0.9922, -1.0000,  ..., -0.9373, -1.0000, -0.7020],\n         [-0.9843, -1.0000, -1.0000,  ..., -0.9059, -0.9686, -0.7255],\n         [-0.9843, -1.0000, -1.0000,  ..., -0.9216, -0.8902, -0.9373],\n         ...,\n         [-0.9922, -0.9765, -0.9529,  ..., -0.9843, -0.9765, -0.9843],\n         [-1.0000, -1.0000, -0.9686,  ..., -0.9686, -1.0000, -0.8196],\n         [-0.7255, -0.8353, -1.0000,  ..., -0.9373, -0.7490, -0.4824]]]), 7), (tensor([[[-0.9922, -0.9843, -0.9608,  ..., -0.9294, -1.0000, -0.7020],\n         [-0.9686, -0.9451, -0.9451,  ..., -0.9216, -0.9843, -0.7333],\n         [-0.9686, -0.9608, -0.9451,  ..., -0.9216, -0.9451, -0.9608],\n         ...,\n         [-0.9765, -0.9922, -0.9922,  ..., -0.9608, -0.9373, -0.9843],\n         [-1.0000, -1.0000, -0.9843,  ..., -0.9373, -1.0000, -0.8039],\n         [-0.7098, -0.8118, -0.9843,  ..., -0.8980, -0.7412, -0.4745]],\n\n        [[-0.8824, -0.9529, -0.9922,  ..., -0.9608, -0.9765, -0.5059],\n         [-0.9608, -1.0000, -1.0000,  ..., -0.9608, -0.9922, -0.6863],\n         [-0.9922, -1.0000, -1.0000,  ..., -0.9451, -0.9608, -0.9686],\n         ...,\n         [-0.9765, -0.9922, -0.9922,  ..., -0.9686, -0.9451, -0.9529],\n         [-0.9922, -1.0000, -0.9843,  ..., -0.9765, -1.0000, -0.7176],\n         [-0.5137, -0.7569, -0.9843,  ..., -0.8980, -0.6471, -0.2314]],\n\n        [[-1.0000, -0.9922, -0.9922,  ..., -0.9686, -1.0000, -0.6941],\n         [-0.9765, -0.9765, -0.9843,  ..., -0.9294, -0.9922, -0.7569],\n         [-0.9765, -0.9843, -0.9843,  ..., -0.9294, -0.9451, -0.9922],\n         ...,\n         [-0.9686, -0.9922, -0.9922,  ..., -0.9922, -0.9843, -1.0000],\n         [-1.0000, -1.0000, -0.9843,  ..., -0.9686, -1.0000, -0.8118],\n         [-0.7098, -0.8118, -0.9843,  ..., -0.9216, -0.7490, -0.4824]]]), 8), (tensor([[[-0.6941, -1.0000, -0.9216,  ..., -1.0000, -0.9922, -1.0000],\n         [-0.7176, -0.9686, -0.9294,  ..., -0.9922, -0.9765, -0.9843],\n         [-0.9451, -0.9373, -0.9373,  ..., -0.9922, -0.9922, -0.9843],\n         ...,\n         [-0.9922, -0.9529, -0.9686,  ..., -0.8667, -0.8902, -0.9059],\n         [-0.8118, -1.0000, -0.9608,  ..., -0.8980, -0.9529, -1.0000],\n         [-0.4902, -0.7490, -0.8902,  ..., -0.9608, -0.8039, -0.7098]],\n\n        [[-0.5216, -0.9843, -0.9608,  ..., -0.9843, -0.9451, -0.8745],\n         [-0.6941, -1.0000, -0.9765,  ..., -1.0000, -0.9922, -0.9529],\n         [-0.9765, -0.9765, -0.9686,  ..., -0.9922, -1.0000, -0.9922],\n         ...,\n         [-0.9922, -0.9686, -0.9608,  ..., -0.9686, -0.9765, -0.9843],\n         [-0.7333, -1.0000, -0.9686,  ..., -0.9843, -1.0000, -1.0000],\n         [-0.2157, -0.6235, -0.8667,  ..., -1.0000, -0.7882, -0.5451]],\n\n        [[-0.6941, -1.0000, -0.9765,  ..., -1.0000, -0.9922, -0.9922],\n         [-0.7569, -0.9922, -0.9451,  ..., -0.9922, -0.9529, -0.9529],\n         [-1.0000, -0.9608, -0.9529,  ..., -0.9843, -0.9686, -0.9608],\n         ...,\n         [-0.9765, -0.9137, -0.9137,  ..., -0.9529, -0.9529, -0.9608],\n         [-0.8039, -1.0000, -0.9294,  ..., -0.9843, -1.0000, -1.0000],\n         [-0.4902, -0.7569, -0.9059,  ..., -1.0000, -0.8353, -0.7176]]]), 9), (tensor([[[-0.7020, -1.0000, -0.9373,  ..., -1.0000, -0.9922, -0.9922],\n         [-0.7255, -0.9922, -0.9529,  ..., -0.9843, -0.9529, -0.9608],\n         [-0.9451, -0.9529, -0.9529,  ..., -0.9843, -0.9608, -0.9529],\n         ...,\n         [-0.9373, -0.9059, -0.9059,  ..., -0.9451, -0.9373, -0.9373],\n         [-0.7804, -0.9843, -0.8902,  ..., -0.9373, -0.9608, -0.9922],\n         [-0.4667, -0.7176, -0.8745,  ..., -0.9529, -0.7961, -0.7020]],\n\n        [[-0.5059, -0.9765, -0.9529,  ..., -0.9529, -0.9059, -0.8353],\n         [-0.6863, -1.0000, -0.9843,  ..., -0.9843, -0.9765, -0.9059],\n         [-0.9765, -0.9765, -1.0000,  ..., -0.9922, -0.9765, -0.9608],\n         ...,\n         [-0.9373, -0.9529, -0.9686,  ..., -0.9608, -0.9529, -0.9529],\n         [-0.7255, -1.0000, -0.9843,  ..., -0.9294, -0.9843, -0.9529],\n         [-0.2392, -0.6471, -0.9059,  ..., -0.9294, -0.7176, -0.4824]],\n\n        [[-0.6941, -1.0000, -0.9529,  ..., -1.0000, -0.9922, -1.0000],\n         [-0.7490, -0.9922, -0.9529,  ..., -1.0000, -0.9608, -0.9608],\n         [-0.9765, -0.9451, -0.9765,  ..., -1.0000, -0.9843, -0.9686],\n         ...,\n         [-0.9608, -0.9216, -0.9294,  ..., -0.9608, -0.9294, -0.9216],\n         [-0.8039, -1.0000, -0.9137,  ..., -0.9686, -0.9686, -0.9843],\n         [-0.4824, -0.7333, -0.8980,  ..., -0.9686, -0.7961, -0.7020]]]), 10), (tensor([[[-0.7176, -0.8275, -0.9922,  ..., -0.9137, -0.7333, -0.4745],\n         [-1.0000, -1.0000, -0.9686,  ..., -0.9059, -0.9686, -0.7725],\n         [-0.9765, -0.9765, -0.9608,  ..., -0.9137, -0.8902, -0.9216],\n         ...,\n         [-0.6863, -0.6941, -0.7255,  ..., -0.9451, -0.9294, -0.9216],\n         [-0.7176, -0.6941, -0.7647,  ..., -0.9373, -0.9686, -0.7020],\n         [-0.8431, -0.7804, -0.8039,  ..., -0.9373, -1.0000, -0.6941]],\n\n        [[-0.5451, -0.7647, -0.9843,  ..., -0.9059, -0.6235, -0.2235],\n         [-1.0000, -1.0000, -0.9529,  ..., -0.9686, -1.0000, -0.6941],\n         [-0.9686, -0.9608, -0.9451,  ..., -0.9843, -0.9451, -0.9373],\n         ...,\n         [-0.9059, -0.8667, -0.8588,  ..., -0.9922, -0.9843, -0.9765],\n         [-0.8118, -0.8667, -0.8588,  ..., -0.9765, -0.9922, -0.6706],\n         [-0.7490, -0.8431, -0.8667,  ..., -0.9529, -0.9765, -0.4902]],\n\n        [[-0.7098, -0.8275, -1.0000,  ..., -0.9294, -0.7490, -0.4824],\n         [-1.0000, -1.0000, -0.9843,  ..., -0.9608, -1.0000, -0.8039],\n         [-0.9608, -0.9765, -0.9765,  ..., -0.9922, -0.9686, -0.9686],\n         ...,\n         [-0.9373, -0.9294, -0.9373,  ..., -0.9843, -0.9529, -0.9843],\n         [-0.9686, -0.9608, -0.9608,  ..., -0.9529, -0.9922, -0.7490],\n         [-0.9922, -0.9765, -0.9843,  ..., -0.9608, -1.0000, -0.7020]]]), 11), (tensor([[[-0.7020, -1.0000, -0.9373,  ..., -0.9843, -0.9765, -0.9843],\n         [-0.7098, -0.9765, -0.9216,  ..., -0.9686, -0.9059, -0.8980],\n         [-0.9059, -0.8824, -0.8902,  ..., -0.9843, -0.9216, -0.8745],\n         ...,\n         [-0.8980, -0.8353, -0.8275,  ..., -0.8588, -0.8431, -0.8431],\n         [-0.7725, -0.9451, -0.8275,  ..., -0.8431, -0.8431, -0.9216],\n         [-0.4745, -0.7333, -0.8431,  ..., -0.8745, -0.7255, -0.6706]],\n\n        [[-0.4902, -0.9608, -0.9451,  ..., -0.9765, -0.9451, -0.8667],\n         [-0.6706, -0.9922, -0.9686,  ..., -0.9686, -0.9843, -0.9137],\n         [-0.9373, -0.9686, -0.9765,  ..., -0.9843, -0.9765, -0.9608],\n         ...,\n         [-0.9216, -0.9216, -0.9451,  ..., -0.9529, -0.9686, -0.9843],\n         [-0.7333, -1.0000, -0.9608,  ..., -0.9373, -0.9922, -1.0000],\n         [-0.2627, -0.6706, -0.9137,  ..., -0.9686, -0.7647, -0.5294]],\n\n        [[-0.7176, -1.0000, -0.9529,  ..., -0.9529, -0.9843, -0.9922],\n         [-0.7647, -0.9922, -0.9529,  ..., -0.9294, -0.9137, -0.9216],\n         [-0.9686, -0.9843, -0.9922,  ..., -0.9451, -0.9294, -0.9294],\n         ...,\n         [-0.9373, -0.9373, -0.9451,  ..., -0.9216, -0.9216, -0.9451],\n         [-0.7961, -1.0000, -0.9216,  ..., -0.9059, -0.9294, -0.9922],\n         [-0.4745, -0.7490, -0.9137,  ..., -0.9451, -0.7804, -0.7020]]]), 12)]\nData loaders ready to read /home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/7968\n"
     ]
    }
   ],
   "source": [
    "img_size=(128,128)\n",
    "\n",
    "# image=ImageFolder('/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/') #Picks up 3590 pictures, directory list has lenght 3637 however \n",
    "\n",
    "image_directory='/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/7968'\n",
    "classes= sorted(os.listdir(image_directory))\n",
    "\n",
    "def load_dataset(data_path):\n",
    "    # Load all the images\n",
    "    transformation = transforms.Compose([\n",
    "        # Randomly augment the image data\n",
    "            # Random horizontal flip\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "            # Random vertical flip\n",
    "        transforms.RandomVerticalFlip(0.3),\n",
    "        # transform to tensors\n",
    "        transforms.ToTensor(),\n",
    "        # Normalize the pixel values (in R, G, and B channels)\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    # Load all of the images, transforming them\n",
    "    full_dataset = torchvision.datasets.ImageFolder(\n",
    "        root=data_path,\n",
    "        # transform=transformation\n",
    "    )\n",
    "    \n",
    "    \n",
    "\n",
    "    full_dataset_v2 = []   \n",
    "    for i in range(len(full_dataset)): \n",
    "        temp=transformation(resize_image(full_dataset[i][0]))\n",
    "        full_dataset_v2.append((temp,i)) \n",
    "    \n",
    "    full_dataset=full_dataset_v2\n",
    "\n",
    "    print(full_dataset)\n",
    "    # Split into training (70% and testing (30%) datasets)\n",
    "    train_size = int(0.7 * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    \n",
    "    # use torch.utils.data.random_split for training/test split\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "    \n",
    "    # define a loader for the training data we can iterate through in 50-image batches\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=50,\n",
    "        num_workers=0,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # define a loader for the testing data we can iterate through in 50-image batches\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=50,\n",
    "        num_workers=0,\n",
    "        shuffle=False\n",
    "    )\n",
    "        \n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "# Get the iterative dataloaders for test and training data\n",
    "train_loader, test_loader = load_dataset(image_directory)\n",
    "batch_size = train_loader.batch_size\n",
    "print(\"Data loaders ready to read\", image_directory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset ImageFolder\n    Number of datapoints: 3590\n    Root location: /home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/\n3637\n3589\n[(<PIL.Image.Image image mode=RGB size=128x128 at 0x7FCB982F4950>, 0), (<PIL.Image.Image image mode=RGB size=128x128 at 0x7FCB9817DC50>, 1), (<PIL.Image.Image image mode=RGB size=128x128 at 0x7FCB98AD6CD0>, 2), (<PIL.Image.Image image mode=RGB size=128x128 at 0x7FCB98A55410>, 3), (<PIL.Image.Image image mode=RGB size=128x128 at 0x7FCB982DCB90>, 4), (<PIL.Image.Image image mode=RGB size=128x128 at 0x7FCBF8644750>, 5), (<PIL.Image.Image image mode=RGB size=128x128 at 0x7FCB983132D0>, 6), (<PIL.Image.Image image mode=RGB size=128x128 at 0x7FCB9A76CB90>, 7), (<PIL.Image.Image image mode=RGB size=128x128 at 0x7FCB9961A590>, 8), (<PIL.Image.Image image mode=RGB size=128x128 at 0x7FCB98421390>, 9), (<PIL.Image.Image image mode=RGB size=128x128 at 0x7FCB9A425090>, 10), (<PIL.Image.Image image mode=RGB size=128x128 at 0x7FCB9849DF50>, 11), (<PIL.Image.Image image mode=RGB size=128x128 at 0x7FCBC9EB5E50>, 12)]\n"
     ]
    }
   ],
   "source": [
    "print(ImageFolder(image_directory))\n",
    "print(len(galaxy_list))\n",
    "print(len(np.unique(galaxy_list)))\n",
    "full_dataset = torchvision.datasets.ImageFolder(\n",
    "        root='/home/juanp/sas/dr15/manga/spectro/redux/v2_4_3/7968',\n",
    "        # transform=transformation\n",
    "    ) \n",
    "\n",
    "full_dataset_v2 = []   \n",
    "for i in range(len(full_dataset)): \n",
    "    full_dataset_v2.append((resize_image(full_dataset[i][0]) , i)) \n",
    "\n",
    "print(full_dataset_v2)\n",
    "\n",
    "\n",
    "# print(full_dataset[0][1])\n",
    "# for i in range(len(full_dataset)): \n",
    "#         full_dataset[i] = (resize_image(full_dataset[i][0]) , 0) \n",
    "        # full_dataset[i][0] = resize_image(full_dataset[i][0])\n",
    "        # full_dataset[i][1] = correct_label(correct_manga_id) "
   ]
  },
  {
   "source": [
    "# Defining the Model "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-1332b3e9c8a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;31m# Create an instance of the model class and allocate it to the device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "# Create a neural net class\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    \n",
    "    # Defining the Constructor\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # In the init function, we define each layer we will use in our model\n",
    "        \n",
    "        # Our images are RGB, so we have input channels = 3. \n",
    "        # We will apply 12 filters in the first convolutional layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # A second convolutional layer takes 12 input channels, and generates 24 outputs\n",
    "        self.conv2 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # We in the end apply max pooling with a kernel size of 2\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # A drop layer deletes 20% of the features to help prevent overfitting\n",
    "        self.drop = nn.Dropout2d(p=0.2)\n",
    "        \n",
    "        # Our 562x562 image tensors will be pooled twice with a kernel size of 1. 562/1/1 is 562.\n",
    "        # This means that our feature tensors are now 562 x 562, and we've generated 24 of them\n",
    "        \n",
    "        # We need to flatten these in order to feed them to a fully-connected layer\n",
    "        self.fc = nn.Linear(in_features=128 * 128 * 24, out_features=10)\n",
    "\n",
    "        self.fc1= nn.Linear(in_features=10, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # In the forward function, pass the data through the layers we defined in the init function\n",
    "        \n",
    "        # Use a ReLU activation function after layer 1 (convolution 1 and pool)\n",
    "        x = F.relu(self.pool(self.conv1(x))) \n",
    "        \n",
    "        # Use a ReLU activation function after layer 2\n",
    "        x = F.relu(self.pool(self.conv2(x)))  \n",
    "        \n",
    "        # Select some features to drop to prevent overfitting (only drop during training)\n",
    "        x = F.dropout(self.drop(x), training=self.training)\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(-1, 128 * 128 * 24)\n",
    "        # Feed to fully-connected layer to predict class\n",
    "        x = self.fc(x)\n",
    "        # Return class probabilities via a log_softmax function\n",
    "        x=F.relu(x) \n",
    "        x= self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "device = \"cpu\"\n",
    "if (torch.cuda.is_available()):\n",
    "    # if GPU available, use cuda (on a cpu, training will take a considerable length of time!)\n",
    "    device = \"cuda\"\n",
    "\n",
    "# Create an instance of the model class and allocate it to the device\n",
    "model = Net(num_classes=len(classes)).to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "source": [
    "# Creating Training Loop/Function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    print(\"Epoch:\", epoch)\n",
    "    # Process the images in batches\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "        # Use the CPU or GPU as appropriate\n",
    "        # Recall that GPU is optimized for the operations we are dealing with\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Reset the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Push the data forward through the model layers\n",
    "    \n",
    "        output = model(data)\n",
    "\n",
    "        \n",
    "        # Get the loss\n",
    "        loss = loss_criteria(output, target)\n",
    "\n",
    "        # Keep a running total\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "       \n",
    "        \n",
    "        # Print metrics so we see some progress\n",
    "        print('\\tTraining batch {} Loss: {:.6f}'.format(batch_idx + 1, loss.item()))\n",
    "            \n",
    "    # return average loss for the epoch\n",
    "    avg_loss = train_loss / (batch_idx+1)\n",
    "    print('Training set: Average loss: {:.6f}'.format(avg_loss))\n",
    "    return avg_loss"
   ]
  },
  {
   "source": [
    "# Create Test Function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    # Switch the model to evaluation mode (so we don't backpropagate or drop)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        batch_count = 0\n",
    "        for data, target in test_loader:\n",
    "            batch_count += 1\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # Get the predicted classes for this batch\n",
    "            output = model(data)\n",
    "            \n",
    "            # Calculate the loss for this batch\n",
    "            test_loss += loss_criteria(output, target).item()\n",
    "            \n",
    "            # Calculate the accuracy for this batch\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            correct += torch.sum(target==predicted).item()\n",
    "\n",
    "    # Calculate the average loss and total accuracy for this epoch\n",
    "    avg_loss = test_loss / batch_count\n",
    "    print('Validation set: Average loss: {:.6f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        avg_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    # return average loss for the epoch\n",
    "    return avg_loss"
   ]
  },
  {
   "source": [
    "# Training the Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training on cuda\nEpoch: 1\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-2dac359f1372>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training on'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mepoch_nums\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-2314c7f2506f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Use the CPU or GPU as appropriate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Recall that GPU is optimized for the operations we are dealing with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Reset the optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "# Use an \"Adam\" optimizer to adjust weights\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Specify the loss criteria\n",
    "loss_criteria = nn.MSELoss()\n",
    "\n",
    "# Track metrics in these arrays\n",
    "epoch_nums = []\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "\n",
    "\n",
    "# Train over 10 epochs (We restrict to 10 for time issues)\n",
    "epochs = 10\n",
    "print('Training on', device)\n",
    "for epoch in range(1, epochs + 1):\n",
    "        train_loss = train(model, device, train_loader, optimizer, epoch)\n",
    "        test_loss = test(model, device, test_loader)\n",
    "        epoch_nums.append(epoch)\n",
    "        training_loss.append(train_loss)\n",
    "        validation_loss.append(test_loss)"
   ]
  }
 ]
}